---
title: "Modelling spatial variability of Municipal Council election turnout in the Netherlands"
author: "Max van den Elsen (2590611), Sander Engelberts (1422138), and Thom Venema (1157485)"
date: 'April 2022'
output: html_document
---
Term project for the MSc Applied Data Science course Spatial statistics and machine learning at Utrecht University. 

The code in this notebook is inspired by provided code in the practicals of this course, created by its teachers. 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading required libraries
This code block loads the required libraries and will ask to install them when these aren't yet.
```{r, , include=FALSE}
# include=FALSE makes sure the output of loading/installing isn't printed

# Install packages if required
if (!require("tidymodels")) install.packages("tidymodels") # For creating modelling workflows
if (!require("easypackages")) install.packages("easypackages") # For easy loading of packages
if (!require("sf")) install.packages("sf") #main GIS package
if (!require("sp")) install.packages("sp") #needed for some GIS operation, will not be in use from 2023
if (!require("spdep")) install.packages("spdep") # Neighborhood analysis in R
if (!require("spatialreg")) install.packages("spatialreg") # Spatial modelling such as lag, error
if (!require("spatialsample")) install.packages("spatialsample") # Spatial cross validation
if (!require("ranger")) install.packages("ranger") # Grid tuning
if (!require("spgwr")) install.packages("spgwr") # GWR modelling
if (!require("RColorBrewer")) install.packages("RColorBrewer") # Getting interesting color
if (!require("tmap")) install.packages("tmap") # Mapping package
if (!require("mapview")) install.packages("mapview") # Mapping package
if (!require("car")) install.packages("car") # Some base regression functions
if (!require("cowplot")) install.packages("cowplot") # Some base regression functions
if (!require("leafsync")) install.packages("leafsync") # Using with mapview
if (!require("leaflet.extras2")) install.packages("leaflet.extras2") #using with mapview
if (!require("modelStudio")) install.packages("modelStudio") # Creating interactive model explaining dashboard for random forest
if (!require("DALEX")) install.packages("DALEX") # Exploring feature importance based on permutation for random forest
if (!require("DALEXtra")) install.packages("DALEXtra") # Exploring feature importance based on permutation for random forest
if (!require("vip")) install.packages("vip") # Exploring feature importance based on impurity for random forest
if (!require("performance")) install.packages("performance") # For checking assumptions linear regression
if (!require("see")) install.packages("see") # For checking assumptions linear regression

# Load packages
easypackages::packages ("tidymodels", "sf", "sp", "spdep", "spatialreg", "spatialsample", "spgwr", "ranger", "tmap", "mapview", "car", "RColorBrewer", "tidyverse", "cowplot", "leafsync", "leaflet.extras2", "mapview", "modelStudio", "DALEX", "DALEXtra", "vip", "performance", "see") 

# Clean R environment
rm(list=ls())
```

## Load and inspect processed data
The Municipal Council election turnout in the Netherlands of 2022 has been processed into a dataset with the file `opkomst_per_stembureau.R`. This coupled the turnout at polling stations to their location and cleaned the data. Next, this data was aggregated to neighbourhoods in the Netherlands using Thiessen polygons around the polling stations and a weighted average over these polygons a neighbourhood area overlaps. For these neighbourhoods also the independent variables were retrieved from CBS to create the final dataset that will be used for our models. Here now first load and inspect that data.

```{r}
# Loading ShapeFile with processed data
neighbourhood_data <- read_sf(file.path("wijk_statistics", "CBS_turnout_Wijk.shp"))

# Check the variables
names(neighbourhood_data) # TODO: add an explanation of each variable underneath and preferably change the names to something more sensible and not such a short abbreviation
```

```{r}
# Drop rows that contain one or multiple NA value(S) because otherwise the models can't be trained TODO: impute the NAs and then can remove this
neighbourhood_data <- na.omit(neighbourhood_data)
```

```{r}
# Show data preview
neighbourhood_data 
```

```{r}
# Plot the neighbourhoods
plot(neighbourhood_data$geometry) 
```

```{r}
# Explore the data distributions
# Plot the turnout data
turnout_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="green3", aes(x = to_rati)) +
  xlab("Election turnout fraction") +
  theme_classic()

# Plot the population density variable # TODO: use the actual predictors and add the other interesting ones as well
pop_density_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = bv_dc_2)) +
  xlab("Population per km^2") +
  theme_classic()

male_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = man)) +
  xlab("Registered male sex fraction") +
  theme_classic()

female_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = vrouw)) +
  xlab("Registered female sex fraction") +
  theme_classic()

p0_15_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_0_15_)) +
  xlab("Percentage age 0-15 year") +
  theme_classic()

p15_25_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_15_25)) +
  xlab("Percentage age 15-25 year") +
  theme_classic()

p25_45_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_25_45)) +
  xlab("Percentage age 25-45 year") +
  theme_classic()

p45_65_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_45_65)) +
  xlab("Percentage age 45-65 year") +
  theme_classic()

p65_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_.65_j)) +
  xlab("Percentage age >65 year") +
  theme_classic()

p_unmarried_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_nghwd)) +
  xlab("Percentage unmarried") +
  theme_classic()

p_married_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_gehwd)) +
  xlab("Percentage married") +
  theme_classic()

p_divorced_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_gschd)) +
  xlab("Percentage divorced") +
  theme_classic()

p_widow_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_vrwdw)) +
  xlab("Percentage widow") +
  theme_classic()

p_western_imm_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_i_wst)) +
  xlab("Percentage western immigrant") +
  theme_classic()

p_not_western_imm_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p__n_ws)) +
  xlab("Percentage not western immigrant") +
  theme_classic()

n_company_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = antl_bd)) +
  xlab("Number of companies") +
  theme_classic()

avg_house_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = gm_wn_w)) +
  xlab("Average house price (*1000)") +
  theme_classic()

n_working_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = ant_nk_)) +
  xlab("Number of income earners in household") +
  theme_classic()

avg_income_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = gm_nk__)) +
  xlab("Average income of income earners (*1000)") +
  theme_classic()

p_low_income_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_lg_nk)) +
  xlab("Percentage of low income households") +
  theme_classic()

p_high_income_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_hg_nk)) +
  xlab("Percentage of high income households") +
  theme_classic()

p_aow_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = aow_utk)) +
  xlab("Percentage of people with AOW") +
  theme_classic()

d_supermarked_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = afst__5)) +
  xlab("Distance to closest supermarket within 5km") +
  theme_classic() # TODO: is this and highschool one the number within 5km??

d_highschool_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = vrtg__3)) +
  xlab("Distance to closest highschool within 3km") +
  theme_classic()

# TODO: what is tot_utk? And antl_nw is not interesting for us right as we used it to determine percentages?

# Show the density plots of interesting variables in a grid # TODO: may need to set how many displayed in a row and such
plot_grid(turnout_plot, pop_density_plot, male_plot, female_plot, p0_15_plot, p15_25_plot, p25_45_plot, p45_65_plot, p65_plot, p_unmarried_plot, p_married_plot, p_divorced_plot, p_widow_plot, p_western_imm_plot, p_not_western_imm_plot, n_company_plot, avg_house_plot, n_working_plot, avg_income_plot, p_low_income_plot, p_high_income_plot, p_aow_plot, d_supermarked_plot, d_highschool_plot, labels = "AUTO")
```

```{r}
# TODO: add some more plots with sliders to check specific variable distributions against dependent variable turnout

# Map the dependent variable turnout
turnout_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "to_rati", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,0.2,0.4,0.6,0.8,1,1.5,2)) # TODO: for other vars also check if I need to set some values for the ranges as outliers make the ranges too broad so all same colour in map

# Map interesting independent variables to compare with the spatial distribution of the independent variable # TODO add the other variables as well
pop_density_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "bv_dc_2", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,250,500,750,1000,2500,5000,10000))

male_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "man", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.3,0.4,0.5,0.6,0.7,1.0))

female_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "vrouw", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.3,0.4,0.5,0.6,0.7,1.0))

age_0_15_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_0_15_", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

age_15_25_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_15_25", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

age_25_45_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_25_45", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

age_45_65_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_45_65", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

age_65_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_.65_j", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

unmarried_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_nghwd", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.3,0.4,0.5,0.6,0.7,1.0))

married_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_gehwd", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.3,0.4,0.5,0.6,0.7,1.0))

divorced_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_gschd", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

widow_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_vrwdw", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

western_imm_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_i_wst", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

not_western_imm_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p__n_ws", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

company_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "antl_bd", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,250,500,750,1000,2500,5000,10000))

house_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "gm_wn_w", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,150,200,250,300,400,600,1000))

p_income_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "ant_nk_", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,0.25,0.5,0.75,1.0,1.25,1.5,2))

income_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "gm_nk__", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,20,25,30,35,40,50,100))

low_income_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_lg_nk", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,0.2,0.3,0.4,0.5,0.6,0.7,1.0))

high_income_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_hg_nk", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,0.2,0.3,0.4,0.5,0.6,0.7,1.0))

aow_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "aow_utk", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

supermarket_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "afst__5", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,20,40,60,80,100,250))

highschool_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "vrtg__3", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,20,40,60,80,100,250))
```

```{r}
# Display two maps with a slider to compare the spatial distribution of the variables in all the neighborhoods # TODO: do this for combinations of all other interesting independent variables against the turnout (and maybe some relations between some of the predictor variables)
#turnout_map | pop_density_map # TODO: does work when just showing one map, but maybe due to the missing values not being in this newest data
turnout_map

pop_density_map

male_map

female_map

age_0_15_map

age_15_25_map

age_25_45_map

age_45_65_map

age_65_map

unmarried_map

married_map

divorced_map
```

```{r}
widow_map

western_imm_map

not_western_imm_map

company_map

house_map

p_income_map

income_map

low_income_map

high_income_map

aow_map

supermarket_map

highschool_map
```

## Pre-process data
Pre-process the data by creating a training and test dataset, normalizing the variables, and creating a model recipe with the model equation. Additionally,  cross validation splits will be created with one taking into account spatial coordinates and the other one not, to check for difference in tuned parameters and model performance.

```{r}
# Set seed for reproducible results
set.seed(123)

# TODO: potentially drop geometry column if exists and needed (was just for easy handling in the model they said)

# Determine coordinates of neighbourhood centroids to split on with spatial cross validation
centroid_coords <- st_coordinates(st_centroid(neighbourhood_data$geometry))
# Need to get integers instead of doubles, and add to dataframe
neighbourhood_data$X_centroid <- centroid_coords[,c("X")]
neighbourhood_data$Y_centroid <- centroid_coords[,c("Y")]

# Split the data into a training (75%) and test (25%) set using stratification on the dependent variable (turnout) to have a representative test sample
data_split <- rsample::initial_split(neighbourhood_data, strata = "to_rati", prop = 0.75)
train_data <- rsample::training(data_split)
test_data  <- rsample::testing(data_split)

# Declare the set explicit
train.set <- train_data
test.set <- test_data
```

```{r}
# For the training dataset, create cross validation splits
# Create split without spatial cross-validation, but consider the dependent variable on which to stratify. Here the number of samples per fold is relatively equal, whereas with spatial cross-validation this is less the case
cv_splits <- rsample::vfold_cv(train.set, strata = "to_rati", k = 10) #here K is the number of fold, k=10 is ten fold CV
print(cv_splits)
```

```{r}
# Create split with spatial cross-validation by clustering coordinate information
cv_spatial_folds <- spatial_clustering_cv(data.frame(train.set), coords = c("X_centroid", "Y_centroid"), v = 10)
print (cv_spatial_folds) 
```

Now the data is ready, the model recipe is defined.
```{r}
# Set the equation model recipe for predicting the dependent variable turnout
model_eq <- to_rati ~ bv_dc_2 + man + vrouw + p_0_15_ + p_15_25 + p_25_45 + p_45_65 + p_.65_j + p_nghwd + p_gehwd + p_gschd + p_vrwdw + p_i_wst + p__n_ws + antl_bd + gm_wn_w + ant_nk_ + gm_nk__ + p_lg_nk + p_hg_nk + aow_utk + afst__5 + vrtg__3 + tot_utk
model_rec <- recipe(model_eq, data = train.set) %>%
  # Normalize the predictor variables using z-normalization
  step_zv(all_predictors()) %>%
  # Centralize some predictors # TODO: example did this only for some
  step_center(all_predictors()) %>%
  # Scale predictors with large values # TODO: example did this only for some
  step_scale(all_predictors())

# Inspect the final recipe by first preparing and then juicing it using glimpse, which shows the model structure for some samples
glimpse(model_rec %>% prep() %>% juice())
```

## Set up workflows for training models
Create the model workflows which will be used for training and predicting different models using the recipe, and set up grid search with a cross validation process for hyperparameter tuning. This then results in the final, optimal models to employ. Below first the model plans are created for linear regression, geographically weighted regression, and random forest models.

```{r}
# TODO: fix that GWR works and the RMSE and such can still be plotted and nice cross validation for hyperparameters
# Prepare for training Geographically weighted regression model. This can't be done using the tidymodels package like the Linear regression and Random forest will use afterwards
# Before doing analysis for GWR the sf polygon object must be converted into a sp spatial object because the spgwr package usually works on sp objects
train.set_sp <- as_Spatial(train.set) # TODO: likely plug in the full neighbourhoods_data dataset in here
# Select optimal bandwidth for adaptive kernel (so k nearest neighbourhoods)
bandwidth <- gwr.sel(prep(model_rec), 
                data = train.set_sp,
                longlat = TRUE, # TODO: may be that we need to change CRS to WG84 from RD New
                adapt = TRUE, 
                gweight = gwr.Gauss) 
```
```{r}
# View optimum bandwidth (proportion of observations)
bandwidth # TODO: check if this value makes sense -> is little pattern found due to the outliers of >200%? So just set all that are above 100% to 100% turnout or such?

# Determine number nearest neighbourhood observations to include 
bandwidth * nrow(neighbourhood_data)
```
```{r}
# Train Geographically weighted regression model
gwr <- gwr(prep(model_rec), data = train.set_sp, longlat = TRUE, gweight = gwr.Gauss, hatmatrix=TRUE, se.fit=TRUE, bandwidth = bandwidth) # TODO: all errors for points, possibly due to dropped NA valued rows (so no tesselation anymore)
```
```{r}
# Show summary of Geographically weighted regression model
gwr
```

```{r}
# Predict outcomes of Geographically weighted regression on test dataset
# TODO: this does not seem to be an actual thing to do with GWR, so just plug in the full dataset instead of only training data. Ask teacher! And is validation then just the R2 map and such? So basically this being more of an explorative model rather than predicting for new locations (would make sense)? In that case also use AIC or something like that to check which model performs best (for the tidymodelsand perhaps also this one likely with glance function from broom library https://broom.tidymodels.org/articles/broom.html)
```

```{r}
# Create the model plans, indicating which types of models to fit and what hyperparameters to tune

# Linear regression plan
lm_plan <- 
  linear_reg() %>% 
  set_engine("lm")

# Geographically weighted regression plan # TODO: may need to convert data into spatial object still, or supply coords instead # TODO: possible also add a SGWR model here and in the other code blocks to allow some variables to be stationary and hence reducing model complexity
# gwr_plan <- gwr(prep(model_rec), data = as_Spatial(train.set), longlat = TRUE, gweight = tune(), hatmatrix=TRUE, se.fit=TRUE, adapt = tune())
# TODO: fix that this works, and this is RD New, not Lonlat if that matters
# TODO: there are many missing values still that Max has to impute, so that is likely why the error "data matrix rows mismatch" pops up as all values have to be available in GWR people say on internet

# Random forest plan
rf_plan <- parsnip::rand_forest() %>%
  parsnip::set_args(mtry  = tune()) %>%
  parsnip::set_args(min_n = tune()) %>%
  parsnip::set_args(trees = 2000) %>% # Setting the first search with 2000 trees # TODO: could tune this as well but that makes the tuning time much much longer probably
  parsnip::set_engine("ranger", importance = "permutation") %>% 
  parsnip::set_mode("regression")
```


For the hyperparameters that are set to be tuned above, set up the grid search combinations to use for tuning. 
```{r}
# Use the expansion option for setting the grids # TODO: decide on which option to select
# Geographically weighted regression
gwr_grid <- expand.grid (gweight = c(gwr.Gauss, gwr.bisquare), # TODO: check if this works for varying shape of kernel
                         adapt = c(10, 50, 100, 500)) # TODO: set this based on how many neighbourhoods we have

# Random forest grid
rf_grid <- expand.grid (mtry = c(3,6,9), 
                       min_n = c(100,500,800)) # TODO: set this based on how many neighbourhoods we have
```

Now we can create the workflow for training the models to match the model recipe with the model plans.

```{r}
# Set model workflows
# Linear regression
lm_wf <-
  workflows::workflow() %>% 
  add_recipe(model_rec) %>% 
  add_model(lm_plan)

# Geographically weighted regression # TODO: everywhere uncomment GWR and see if can get working as is not a supported tidymodels model so may also need to do do the hyperparameter cross validation separately and train separately from this tidymodels workflow
# gwr_wf <-
#  workflows::workflow() %>%
#  add_recipe(model_rec) %>%
#  add_model(gwr_plan)

# Random forest
rf_wf <-
  workflows::workflow() %>% 
  add_recipe(model_rec) %>% 
  add_model(rf_plan)
```

## Determine the best tuned hyperparameters and corresponding models
The created workflows are now used to tune the models to their grids to be able to extract the optimal hyperparameters and their corresponding models. This is done using the cross validation datasets.

```{r}
# Train linear regression (no hyperparameters to tune, but recipe coefficients instead; grid value states how many coefficient combinations need to be created automatically)  # TODO: likely just do this on training data, as nothing to cross validate here, so then also remove the spatial option elsewhere # TODO could tune recipe coefficients on CV but that didn't work yet (maybe due to missing values as well)
#lm_tuned <- lm_plan %>% fit(model_eq, data = train.set) # Without spatial cross-validation
lm_tuned <- tune_grid(lm_wf, resamples = cv_splits, grid = 10, control=control_grid(save_pred = TRUE))
lm_tuned_spatial <- tune_grid(lm_wf, resamples = cv_spatial_folds, grid = 10, control=control_grid(save_pred = TRUE))
#lm_tuned_spatial <- lm_plan %>% fit(model_eq, data = cv_spatial_folds) # With spatial cross-validation 

# Tune model hyperparameters
# Geographically weighted regression
# gwr_tuned <- tune_grid(gwr_wf, resamples = cv_splits, grid = gwr_grid) # Without spatial cross-validation
# gwr_tuned_spatial <- tune_grid(gwr_wf, resamples = cv_spatial_folds, grid = gwr_grid) # With spatial cross-validation

# Random forest
rf_tuned <- tune_grid(rf_wf, resamples = cv_splits, grid = rf_grid, control=control_grid(save_pred = TRUE)) # Without spatial cross-validation
rf_tuned_spatial <- tune_grid(rf_wf, resamples = cv_spatial_folds, grid = rf_grid, control=control_grid(save_pred = TRUE)) # With spatial cross-validation 
```

Extract the best hyperparameters from each above tuned models and their corresponding optimal models based on their training performance.
```{r}
# Extract the best parameters based on RMSE, also used for evaluating performance on the test data
# Linear regression # TODO: no tuning done for this with cross validation so can leave out likely (same for after, just get the coefficients if needed)
lm_best_params <- select_best(lm_tuned, metric = "rmse") # Without spatial cross-validation
lm_best_params_spatial <- select_best(lm_tuned_spatial, metric = "rmse") # With spatial cross-validation

# Geographically weighted regression
#gwr_best_params <- select_best(gwr_tuned, metric = "rmse") # Without spatial cross-validation
#gwr_best_params_spatial <- select_best(gwr_tuned_spatial, metric = "rmse") # With spatial cross-validation

# Random forest
rf_best_params <- select_best(rf_tuned, metric = "rmse") # Without spatial cross-validation
rf_best_params_spatial <- select_best(rf_tuned_spatial, metric = "rmse") # With spatial cross-validation
```

```{r}
# Pull best hyperparameter combinations from the 10-fold cross validated predictions
# Linear regression
#lm_best_OOF_preds <- predict(lm_tuned, new_data = test.set) 
lm_best_OOF_preds <- collect_predictions(lm_tuned)# Without spatial cross-validation # TODO: this was not trained on cross validation so also no training error check on validation set. But code of teacher seemed to still have done that though so that is sad as tune_grid is not mentioned there how it is done
lm_best_OOF_preds_spatial <- collect_predictions(lm_tuned_spatial) # With spatial cross-validation

# Geographically weighted regression
# gwr_best_OOF_preds <- collect_predictions(gwr_tuned) %>% 
#   filter(gweight  == gwr_best_params$gweight[1] & adapt == gwr_best_params$adapt[1]) # Without spatial cross-validation
# gwr_best_OOF_preds_spatial <- collect_predictions(gwr_tuned_spatial) %>% 
#   filter(gweight  == gwr_best_params_spatial$gweight[1] & adapt == gwr_best_params_spatial$adapt[1]) # With spatial cross-validation

# Random forest
 rf_best_OOF_preds <- collect_predictions(rf_tuned) %>%
   filter(mtry  == rf_best_params$mtry[1] & min_n == rf_best_params$min_n[1]) # Without spatial cross-validation
rf_best_OOF_preds_spatial <- collect_predictions(rf_tuned_spatial) %>%
  filter(mtry  == rf_best_params_spatial$mtry[1] & min_n == rf_best_params_spatial$min_n[1]) # With spatial cross-validation
```


```{r}
# Retrieve the best parameter models
# Linear regression
lm_best_OOF_preds <- lm_best_OOF_preds %>% dplyr::select(-id,-.config) # Without spatial cross-validation
lm_best_OOF_preds_spatial <- lm_best_OOF_preds_spatial %>% dplyr::select(-id,-.config) # With spatial cross-validation

# Geographically weighted regression
# gwr_best_OOF_preds <- gwr_best_OOF_preds %>% dplyr::select(-id,-.config) # Without spatial cross-validation
# gwr_best_OOF_preds_spatial <- gwr_best_OOF_preds_spatial %>% dplyr::select(-id,-.config) # With spatial cross-validation

# Random forest
rf_best_OOF_preds <- rf_best_OOF_preds %>% dplyr::select(-id,-.config) # Without spatial cross-validation
rf_best_OOF_preds_spatial <- rf_best_OOF_preds_spatial %>% dplyr::select(-id,-.config) # With spatial cross-validation
```

Evaluate performance of these best tuned models on training data.
```{r}
# Make prediction for each model and attach error statistics
OOF_preds <- rbind(
  data.frame(lm_best_OOF_preds %>% dplyr::select(.pred,to_rati),model = "Model-1a_Linear Regression"),
                   data.frame(lm_best_OOF_preds_spatial %>% dplyr::select(.pred,to_rati),model = "Model-1b_Linear Regression spatial"),
  #                  data.frame(gwr_best_OOF_preds %>% dplyr::select(.pred,to_rati),model = "Model-2a_Geographically Weighted Regression"),
  #                  data.frame(gwr_best_OOF_preds_spatial %>% dplyr::select(.pred,to_rati),model = "Model-2b_Geographically Weighted Regression spatial"),
                   data.frame(rf_best_OOF_preds %>% dplyr::select(.pred,to_rati),model = "Model-3a_Random Forest"), 
                   data.frame(rf_best_OOF_preds_spatial %>% dplyr::select(.pred,to_rati),model = "Model-3b_Random Forest spatial")) %>%
  group_by(model) %>% 
  mutate(
    RMSE = yardstick::rmse_vec(to_rati, .pred),
    MAE  = yardstick::mae_vec(to_rati, .pred),
    MAPE = yardstick::mape_vec((to_rati+1), (.pred+1))) %>% 
  ungroup()
```

```{r}
# Plot average squared error (RMSE) for each model 
ggplot(data = OOF_preds %>%
         dplyr::select(model, RMSE) %>%
         distinct() ,
       aes(x = model, y = RMSE, group = 1)) +
  geom_path(color = "green") +
  geom_label(aes(label = round(RMSE,3))) +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Plot mean absolute error (MAE) for each model
ggplot(data = OOF_preds %>%
         dplyr::select(model, MAE) %>%
         distinct() ,
       aes(x = model, y = MAE, group = 1))  +
  geom_path(color = "red") +
  geom_label(aes(label = round(MAE,3))) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# TODO: could also plot MAPE

# Plot predicted versus the observed values for each model in scatter plots
ggplot(OOF_preds, aes(y=.pred , x = to_rati,group = model)) + 
  geom_point(alpha = 0.3) +
  coord_equal() +
  geom_abline(linetype = "dashed",color = "blue") +
  geom_smooth(method="lm", color = "red") +
  facet_wrap(~model,ncol = 3)+
  theme_bw()+
  xlab("Election turnout fraction") + 
  ylim(0, 10)+
  xlim(0, 10)
```

As can be seen, the different models predict differently and have varying level of training errors.

## Evaluate models on test data
To check how well the models generalise to unseen data, the predictions are made for the test data and corresponding errors are determined. For this the models with best parameters are first fit with the full training dataset and not only cross validation folds.
```{r}
# Create final workflow
# Linear regression
lm_best_wf     <- finalize_workflow(lm_wf, lm_best_params) # Without spatial cross-validation
lm_best_wf_spatial     <- finalize_workflow(lm_wf, lm_best_params_spatial) # With spatial cross-validation
# 
# # Geographically weighted regression
# gwr_best_wf     <- finalize_workflow(gwr_wf, gwr_best_params) # Without spatial cross-validation
# gwr_best_wf_spatial     <- finalize_workflow(gwr_wf, gwr_best_params_spatial) # With spatial cross-validation

# Random forest
rf_best_wf     <- finalize_workflow(rf_wf, rf_best_params) # Without spatial cross-validation
rf_best_wf_spatial     <- finalize_workflow(rf_wf, rf_best_params_spatial) # With spatial cross-validation
```

```{r}
# Fit models on full training dataset
# Linear regression
lm_val_fit_geo <- lm_best_wf %>%
  last_fit(split     = data_split,
           #control   = control,
           metrics   = metric_set(rmse, rsq)) # Without spatial cross-validation
lm_val_fit_geo_spatial <- lm_best_wf_spatial %>%
  last_fit(split     = data_split,
           #control   = control,
           metrics   = metric_set(rmse, rsq)) # With spatial cross-validation
# 
# # Geographically weighted regression
# gwr_val_fit_geo <- gwr_best_wf %>% 
#   last_fit(split     = data_split,
#            control   = control,
#            metrics   = metric_set(rmse, rsq)) # Without spatial cross-validation
# gwr_val_fit_geo_spatial <- gwr_best_wf_spatial %>% 
#   last_fit(split     = data_split,
#            control   = control,
#            metrics   = metric_set(rmse, rsq)) # With spatial cross-validation

# Random forest
rf_val_fit_geo <- rf_best_wf %>% 
  last_fit(split     = data_split,
           #control   = control_grid(save_pred = TRUE),
           metrics   = metric_set(rmse, rsq)) # Without spatial cross-validation
rf_val_fit_geo_spatial <- rf_best_wf_spatial %>% 
  last_fit(split     = data_split,
           #control   = control,
           metrics   = metric_set(rmse, rsq)) # With spatial cross-validation
```

```{r}
# Using these final trained models, make predictions for the test dataset and get the best configuration for the test data for required models
# Linear regression
lm_val_pred_geo     <- collect_predictions(lm_val_fit_geo) # Without spatial cross-validation
lm_val_pred_geo_spatial     <- collect_predictions(lm_val_fit_geo_spatial) # With spatial cross-validation
# 
# # Geographically weighted regression
# gwr_val_pred_geo     <- collect_predictions(gwr_val_fit_geo)
# gwr_val_pred_geo <- gwr_val_pred_geo %>% dplyr::select(-id,-.config) # Without spatial cross-validation
# gwr_val_pred_geo_spatial     <- collect_predictions(gwr_val_fit_geo_spatial)
# gwr_val_pred_geo_spatial <- gwr_val_pred_geo_spatial %>% dplyr::select(-id,-.config) # With spatial cross-validation

# Random forest
rf_val_pred_geo     <- collect_predictions(rf_val_fit_geo)
rf_val_pred_geo <- rf_val_pred_geo %>% dplyr::select(-id,-.config) # Without spatial cross-validation
rf_val_pred_geo_spatial     <- collect_predictions(rf_val_fit_geo_spatial)
rf_val_pred_geo_spatial <- rf_val_pred_geo_spatial %>% dplyr::select(-id,-.config) # With spatial cross-validation
```

```{r}
# Aggregate test set predictions (these do not overlap with training prediction set, which is OOF_preds) with error statistics
val_preds <- rbind(
  data.frame(dplyr::select(lm_val_pred_geo, .pred, to_rati), model = "Model-1a_Linear Regression"),
                   data.frame(dplyr::select(lm_val_pred_geo_spatial, .pred, to_rati), model = "Model-1b_Linear Regression spatial"),
  #                  data.frame(dplyr::select(gwr_val_pred_geo, .pred, to_rati), model = "Model-2a_Geographically Weighted Regression"),
  #                  data.frame(dplyr::select(gwr_val_pred_geo_spatial, .pred, to_rati), model = "Model-2b_Geographically Weighted Regression spatial"),
                   data.frame(dplyr::select(rf_val_pred_geo, .pred, to_rati), model = "Model-3a_Random Forest"),
                   data.frame(dplyr::select(rf_val_pred_geo_spatial, .pred, to_rati), model = "Model-3b_Random Forest spatial")) %>% 
  group_by(model) %>% 
  mutate(RMSE = yardstick::rmse_vec(to_rati, .pred),
         MAE  = yardstick::mae_vec(to_rati, .pred),
         MAPE = yardstick::mape_vec((to_rati+1), (.pred+1)),
         absE=abs(to_rati-.pred)) %>% 
  ungroup()
```

```{r}
# Plot average squared error (RMSE) for each model 
ggplot(data = val_preds %>% 
                           dplyr::select(model, RMSE) %>% 
                           distinct() , 
                         aes(x = model, y = RMSE, group = 1))  +
  geom_path(color = "green") +
  geom_label(aes(label = round(RMSE,4))) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Plot mean absolute error (MAE) for each model # TODO: may need to ylim the plots as can otherwise be misleading how much different the values are
ggplot(data = val_preds %>%
         dplyr::select(model, MAE) %>%
         distinct() ,
       aes(x = model, y = MAE,group = 1))  +
  geom_path(color = "red") +
  geom_label(aes(label = round(MAE,3))) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# TODO: could also plot MAPE and absE, and possibly calculate the AIC heuristic, and may be nice to make a ROC curve
# TODO: may want to change xlim to make better visible

# Plot predicted versus the observed values for each model in scatter plots
ggplot(val_preds, aes(y=.pred , x = to_rati,group = model))+ 
  geom_point(alpha = 0.3) +
  coord_equal() +
  geom_abline(linetype = "dashed",color = "red") +
  geom_smooth(method="lm", color = "blue") +
  facet_wrap(~model,ncol = 3)+
  theme_bw()+
  xlab("Election turnout fraction") + 
  ylim(0,10)+
  xlim(0,10)
```
As can be seen, like with the performance on training data, the different models predict differently and have varying level of testing errors.

## Check for spatial autocorrelation with linear regression model
Check if the assumptions of final trained linear regression model hold using this dataset (likely not), by investigating multicollinearity and spatial autocorrelation.
```{r}
# Check assumptions of linear regression like multicollinearity, which occurs when the predictor variables actually predict one another, and due to correlation some predictor variables may also be redundant
# Information from: https://jhudatascience.org/tidyversecourse/model.html 5.14.1.4 and https://cran.r-project.org/web/packages/performance/performance.pdf
lm_val_fit_geo %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>% check_model(panel=FALSE) # Without spatial cross validation
```
```{r} 
lm_val_fit_geo_spatial %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>% check_model(panel=FALSE) # With spatial cross validation
```


```{r}
# Check spatial autocorrelation
# Create Queen's Contiguity adjacency matrix # TODO: can also check for other weight matrices
adjacency_nbq <- poly2nb(neighbourhood_data, queen=TRUE) #Queen's Contiguity neighborhood # TODO: now with the neighbourhoods dropped that have NA values, standard adjacency is not working anymore, so check if works when imputed else use different kind of weight matrix based on distance
adjacency_nbq_w <- nb2listw(adjacency_nbq, style="W") #Queen's neighborhood wights

# Plot adjacent neighbours with line between them
coordsW <- neighbourhood_data%>%
  st_centroid()%>%
  st_geometry()
plot(adjacency_nbq, st_geometry(coordsW), col="red") 
```

```{r}
# Because the moran.test function for retrieving the Moran's I is sensitive to irregularly distributed polygons, here we use a Monte Carlo method to bootstrap different polygon distribution (with moran.mc() function)
# Without spatial cross-validation
mc_global <- moran.mc(lm_val_fit_geo$residuals, adjacency_nbq_w, 2999, alternative="greater")
# TODO: set that 2999 to sensible number

# Plot the  Moran's I
plot(mc_global)

print(mc_global) #As the p value is significant we reject the null hypothesis that there is no significant autocorrelations among the variable, and accept that, the residual has spatial clustering

# Plot the residual on the neighbourhood polygons
neighbourhood_data$res_lm <- residuals(lm_val_fit_geo)
lmres <- qtm(neighbourhood_data, "res_lm")
lmres 
```

```{r}
# With spatial cross-validation
mc_global_spatial <- moran.mc(lm_val_fit_geo_spatial$residuals, adjacency_nbq_w, 2999, alternative="greater")
# TODO: set that 2999 to sensible number

# Plot the  Moran's I
plot(mc_global_spatial)

print(mc_global_spatial) # As the p value is significant we reject the null hypothesis that there is no significant autocorrelations among the variable, and accept that, the residual has spatial clustering

# Plot the residual on the neighbourhood polygons
neighbourhood_data$res_lm_spatial <- residuals(lm_val_fit_geo_spatial)
lmres_spatial <- qtm(neighbourhood_data, "res_lm_spatial")
lmres_spatial 
```

For both linear regression models that are trained on a cross validation split with and without taking the spatial nature of the dataset into account, significant spatial autocorrelation in the data can be concluded.

## Investigate non-stationarity with geographically weighted regression model
Now the geographically weighted regression models are trained, it is interesting to inspect the local patterns that have been found. For this purpose map the coefficients of interesting predictor variables and compare this to a map of the significance of this variable. 
```{r}
# Put the Geographically Weighted Regression with adaptive kernel results in data frame
gwr_out <- as.data.frame(gwr_val_fit_geo$SDF) # Without spatial cross-validation
gwr_out_spatial <- as.data.frame(gwr_val_fit_geo_spatial$SDF) # With spatial cross-validation
```

```{r}
# Join the local R2 for each GWR model to each neighborhood and display its distribution
# Without spatial cross-validation
neighbourhood_data$amb_localR2 <- gwr_out$localR2
mapview::mapview(neighbourhood_data, zcol = "amb_localR2", col.regions=brewer.pal(11, "RdYlGn")) 

# With spatial cross-validation
neighbourhood_data$amb_localR2_spatial <- gwr_out_spatial$localR2
mapview::mapview(neighbourhood_data, zcol = "amb_localR2_spatial", col.regions=brewer.pal(11, "RdYlGn")) 
```

```{r}
#' Create two maps in one venster with a slider to compare Geographically Weighted Regression coefficients of a predictor variable with its significance levels by first joining these values to their respective neighbourhood polygons
#' 
#' @param data Dataset with the polygon geometry information to which to join the coefficient and significance values
#' @param gwr_results Data frame with results of trained Geographically Weighted Regression model. This is different for the model trained using spatial cross-validation and when spatial was not taken into account for cross-validation
#' @param predictor String with the name of the predictor variable to create these maps for
#' @param suffix String (default "") with a suffix for the predictor name when the coefficient and significance values are added as column to data. This can uniquely refer to the model used for training to get unique column names, e.g. "spatial".
#'
map_coefficient_var_sig <- function(data, gwr_results, predictor, suffix="") {
  # Determine the coefficient variability over space for all relevant predictors, after joining that with the neighbourhood polygons. This plot will now only be created and later be shown together with its predictor significance plot
  # Create column name for adding coefficient values to data
  acoef_str <- paste("acoef", predictor, suffix, sep="_") 
  # Join coefficient values with neighbourhoods
  data[acoef_str] <- gwr_results[,predictor]
  # Create map of coefficient values
  gwr_coef <- mapview::mapview(data, zcol = acoef_str)
  
  # Compute and map the statistical significance for variable using t-test. Plot this next to the map with its respective coefficient value distribution
  # Create column names for adding significance values to data
  pred_str_se <- paste(predictor, "se", sep="_")
  pred_str_at <- paste("at", predictor, sep="_")
  pred_str_at_cat <- paste(pred_str_at, "cat", sep="_")
  # Estimate the t-value for variable 
  data$at_Green_avail = gwr_results[,predictor] / gwr_results[,pred_str_se]
  # Categorize the t-value to statistical significance
  data[pred_str_at_cat] <- cut(data[,pred_str_at],
                                    breaks=c(min(data[,pred_str_at]),
                                             -1.96, 1.96,
                                             max(data[,pred_str_at])),
                                    labels=c("sig","nonsig", "sig"))
  # Make plot of the variable significance 
  gwr_sig <- mapview::mapview(data, zcol = pred_str_at_cat)
  
  # Compare the coefficient and significance maps of this variable
  gwr_coef | gwr_sig
}
```

```{r}
# TODO: get a variable that actually exists, and run this function for multiple others too
# Without spatial cross-validation
map_coefficient_var_sig(data=neighbourhood_data, gwr_results=gwr_out, predictor="education", suffix="")

# With spatial cross-validation
map_coefficient_var_sig(data=neighbourhood_data, gwr_results=gwr_out_spatial, predictor="education", suffix="spatial")
```

## Inspect important variables of random forest model
To investigate what variables are most important for the Random Forest model to make its predictions, the feature importance is determined and plotted. This shows which variables were most important in predicting the turnout. The importance is first shown based on the impurity metric and after in an interactive model based on permutation, which is more robust. In this interactive model also the partial dependence of different variables can be explored to check their relations. Note that this can take quite a bit of time to run.
```{r}
# Plot the variable importance based on goodness of split (based on impurity metric) 
# Without spatial cross-validation
rf_val_fit_geo %>% pluck(".workflow", 1) %>% pull_workflow_fit() %>%
vip::vip(num_features = 20, idth = 0.5, aesthetics = list(fill = "purple2"), include_type = T) # TODO: set num_features to sensible value for data # TODO: with linear regression said # pull_workflow_fit() was deprecated so changed for extract_fit_parsnip()
```

```{r}
# Plot the variable importance based on goodness of split (based on impurity metric) 
# With spatial cross-validation
rf_val_fit_geo_spatial %>% pluck(".workflow", 1) %>% pull_workflow_fit() %>% vip::vip(num_features = 19, idth = 0.5, aesthetics = list(fill = "purple2"), include_type = T) # TODO: set num_features to sensible value for data
```

```{r}
# Create model explainer for plotting variable importance based on permutation
# Without spatial cross-validation
predictors <- train.set %>% select(all_of(c("bv_dc_2", "man", "vrouw", "p_0_15_", "p_15_25", "p_25_45", "p_45_65", "p_.65_j", "p_nghwd", "p_gehwd", "p_gschd", "p_vrwdw", "p_i_wst", "p__n_ws", "antl_bd", "gm_wn_w", "ant_nk_", "gm_nk__", "p_lg_nk", "p_hg_nk", "aow_utk", "afst__5", "vrtg__3", "tot_utk"))) 

explainer_RF <- DALEXtra::explain_tidymodels(
  model = rf_val_fit_geo$.workflow[[1]],
  data = predictors,
  y = as.integer(train.set$to_rati*100), # modelStudio wants integers so convert fractions to percentages
  label = "Random Forest",
  verbose = FALSE
)

# Make an interactive dashboard
modelStudio::modelStudio(explainer_RF) # TODO: here is some weird error so not sure if will be possible to make an importance ranking based on permutation instead of impurity
```


```{r}
# Create model explainer for plotting variable importance based on permutation
# With spatial cross-validation
explainer_RF_spatial <- DALEX::explain(
  model = rf_val_pred_geo_spatial,
  data = train.set,
  y = as.integer (train.set$turnout),
  label = "Random Forest",
  verbose = FALSE
)
# Make an interactive dashboard
modelStudio::modelStudio(explainer_RF_spatial)
```