---
title: Modelling spatial variability of Municipal Council election turnout in the
  Netherlands
author: Max van den Elsen (2590611), Sander Engelberts (1422138), and Thom Venema
  (1157485)
date: "April 2022"
output:
  pdf_document: default
  html_document: default
---
Term project for the MSc Applied Data Science course Spatial statistics and machine learning at Utrecht University. 

The code in this notebook is inspired by provided code in the practicals of this course, created by its teachers. 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading required libraries
This code block loads the required libraries and will ask to install them when these aren't yet.
```{r, , include=FALSE}
# include=FALSE makes sure the output of loading/installing isn't printed

# Install packages if required
if (!require("tidymodels")) install.packages("tidymodels") # For creating modelling workflows
if (!require("easypackages")) install.packages("easypackages") # For easy loading of packages
if (!require("sf")) install.packages("sf") #main GIS package
if (!require("sp")) install.packages("sp") #needed for some GIS operation, will not be in use from 2023
if (!require("spdep")) install.packages("spdep") # Neighborhood analysis in R
if (!require("spatialreg")) install.packages("spatialreg") # Spatial modelling such as lag, error
if (!require("spatialsample")) install.packages("spatialsample") # Spatial cross validation
if (!require("ranger")) install.packages("ranger") # Grid tuning
if (!require("spgwr")) install.packages("spgwr") # GWR modelling
if (!require("RColorBrewer")) install.packages("RColorBrewer") # Getting interesting color
if (!require("tmap")) install.packages("tmap") # Mapping package
if (!require("mapview")) install.packages("mapview") # Mapping package
if (!require("car")) install.packages("car") # Some base regression functions
if (!require("cowplot")) install.packages("cowplot") # Some base regression functions
if (!require("leafsync")) install.packages("leafsync") # Using with mapview
if (!require("leaflet.extras2")) install.packages("leaflet.extras2") #using with mapview
if (!require("modelStudio")) install.packages("modelStudio") # Creating interactive model explaining dashboard for random forest
if (!require("DALEX")) install.packages("DALEX") # Exploring feature importance based on permutation for random forest
if (!require("DALEXtra")) install.packages("DALEXtra") # Exploring feature importance based on permutation for random forest
if (!require("vip")) install.packages("vip") # Exploring feature importance based on impurity for random forest
if (!require("performance")) install.packages("performance") # For checking assumptions linear regression
if (!require("see")) install.packages("see") # For checking assumptions linear regression

# Load packages
easypackages::packages ("tidymodels", "sf", "sp", "spdep", "spatialreg", "spatialsample", "spgwr", "ranger", "tmap", "mapview", "car", "RColorBrewer", "tidyverse", "cowplot", "leafsync", "leaflet.extras2", "mapview", "modelStudio", "DALEX", "DALEXtra", "vip", "performance", "see") 

# Clean R environment
rm(list=ls())
```

## Load and inspect processed data
The Municipal Council election turnout in the Netherlands of 2022 has been processed into a dataset with the file `opkomst_per_stembureau.R`. This coupled the turnout at polling stations to their location and cleaned the data. Next, this data was aggregated to neighbourhoods in the Netherlands using Thiessen polygons around the polling stations and a weighted average over these polygons a neighbourhood area overlaps. For these neighbourhoods also the independent variables were retrieved from CBS to create the final dataset that will be used for our models. Here now first load and inspect that data.

```{r}
# Loading ShapeFile with processed data
neighbourhood_data <- read_sf(file.path("neighborhood_stats", "CBS_turnout_neighborhood.shp"))

# Check the variables
names(neighbourhood_data)
```

```{r}
# Change the parameter names to recognisable strings
newnames <- c('ID', 'wijkcode', 'gem_naam', 'bev_dichth_km2', 'aantal_inw', 'man', 'vrouw', 
             'p_0_15_jaar', 'p_15_25_jaar', 'p_25_45_jaar', 'p_45_65_jaar', 'p_65_jaar',
             'p_ongehuwd', 'p_gehuwd', 'p_gescheiden', 'p_verweduwd', 'p_ia_west', 'p_ia_n_west',
             'aantal_bedrijf', 'gem_woning_waarde', 'aant_ink_ont', 'gem_ink_p_o',
             'p_laag_ink', 'p_hoog_ink', 'aow_uitk', 'afst_levensm_5km', 'voortg_ond_3km', 'tot_uitkering', 'p_adults', 'n_turnout', 
             'turnout_ratio', 'dist_NN_voting_station', 'geometry') 

names(neighbourhood_data) <- newnames
```

For each neighbourhood these variables can be described as follows:
* ID : unique id 
* wijkcode : unique neighbourhood code of CBS
* gem_naam : name of municipality the neighbourhood belongs to
* bev_dichth_km2 : number of residents per km^2
* aantal_inw : number of residents
* man : percentage of residents registered as being male sex
* vrouw : percentage of residents registered as being female sex
* p_0_15_jaar : percentage of residents between 0 and 15 year
* p_15_25_jaar : percentage of residents between 15 and 25 year
* p_25_45_jaar : percentage of residents between 25 and 45 year
* p_45_65_jaar : percentage of residents between 45 and 65 year
* p_65_jaar : percentage of residents older than 65 year
* p_ongehuwd : percentage of residents who aren't married
* p_gehuwd : percentage of residents who are married
* p_gescheiden : percentage of residents who are divorced
* p_verweduwd : percentage of residents who are widowed
* p_ia_west : percentage of residents who have a western immigrant background
* p_ia_n_west : percentage of residents who have a non-western immigrant background
* aantal_bedrijf : number of companies
* gem_woning_waarde : average house value
* aant_ink_ont : average number of income earners per household
* gem_ink_p_o : average income per income earner
* p_laag_ink : percentage of residents with a low income
* p_hoog_ink : percentage of residents with a high income
* aow_uitk : percentage of residents with an AOW uitkering
* afst_levensm_5km : minimum distance (in meters) to supermarket within 5km range
* voortg_ond_3km : minimum distance (in meters) to highschool within 3km range
* tot_uitkering : percentage of residents with an AO, WW, or algemene bijstands uitkering
* p_adults : percentage of residents older than 18 year, which is a combination of p_15_25_jaar, p_25_45_jaar, p_45_65_jaar, and p_65_jaar where 70% of p_15_25_jaar is taken into account (so assumed uniform distribution over ages in that range)
* n_turnout : number of registered votes
* turnout_ratio : fraction of registered votes compared to number of residents who are allowed to vote, so n_turnout / p_adults
* dist_NN_voting_station : minimum distance (in meters) to closest voting station from centroid of neighbourhood
* geometry : spatial geometry 


```{r}
# Plot the full dataset
plot(neighbourhood_data$geometry)
```

```{r}
print(paste("There are ", nrow(neighbourhood_data), " neighbourhoods in the original dataset"))
```

```{r}
# Explore the data distributions
# Plot the turnout data
turnout_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="green3", aes(x = turnout_ratio)) +
  xlab("Election turnout fraction") +
  xlim(0, 5)
  theme_classic()

# Plot the population density variable 
pop_density_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = bev_dichth_km2)) +
  xlab("Population per km^2") +
  theme_classic()

male_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = man)) +
  xlab("Registered male sex fraction") +
  theme_classic()

female_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = vrouw)) +
  xlab("Registered female sex fraction") +
  theme_classic()

p0_15_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_0_15_jaar)) +
  xlab("Percentage age 0-15 year") +
  theme_classic()

p15_25_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_15_25_jaar)) +
  xlab("Percentage age 15-25 year") +
  theme_classic()

p25_45_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_25_45_jaar)) +
  xlab("Percentage age 25-45 year") +
  theme_classic()

p45_65_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_45_65_jaar)) +
  xlab("Percentage age 45-65 year") +
  theme_classic()

p65_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_65_jaar)) +
  xlab("Percentage age >65 year") +
  theme_classic()

p_adults_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_adults)) +
  xlab("Percentage adults (age >18 year)") +
  theme_classic()

p_unmarried_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_ongehuwd)) +
  xlab("Percentage unmarried") +
  theme_classic()

p_married_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_gehuwd)) +
  xlab("Percentage married") +
  theme_classic()

p_divorced_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_gescheiden)) +
  xlab("Percentage divorced") +
  theme_classic()

p_widow_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_verweduwd)) +
  xlab("Percentage widow") +
  theme_classic()

p_western_imm_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_ia_west)) +
  xlab("Percentage western immigrant") +
  theme_classic()

p_not_western_imm_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_ia_n_west)) +
  xlab("Percentage not western immigrant") +
  theme_classic()

n_company_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = aantal_bedrijf)) +
  xlab("Number of companies") +
  theme_classic()

avg_house_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = gem_woning_waarde)) +
  xlab("Average house price (*1000)") +
  theme_classic()

n_working_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = aant_ink_ont)) +
  xlab("Number of income earners in household") +
  theme_classic()

avg_income_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = gem_ink_p_o)) +
  xlab("Average income of income earners (*1000)") +
  theme_classic()

p_low_income_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_laag_ink)) +
  xlab("Percentage of low income households") +
  theme_classic()

p_high_income_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = p_hoog_ink)) +
  xlab("Percentage of high income households") +
  theme_classic()

p_aow_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = aow_uitk)) +
  xlab("Percentage of people with AOW") +
  theme_classic()

d_supermarked_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = afst_levensm_5km)) +
  xlab("Distance (in meters) to closest supermarket within 5km") +
  theme_classic() 

d_highschool_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = voortg_ond_3km)) +
  xlab("Distance (in meters) to closest highschool within 3km") +
  theme_classic()

d_NN_voting_station_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = dist_NN_voting_station)) +
  xlab("Distance (in meters) to nearest voting station") +
  theme_classic()

p_uitkering_plot <- ggplot(data = neighbourhood_data) +
  geom_density(alpha=0.8, colour="black", fill="lightblue", aes(x = tot_uitkering)) +
  xlab("Percentage of people with AO, WW, or algemene bijstands uitkering") +
  theme_classic()


# Show the density plots of interesting variables in a grid 
plot_grid(turnout_plot, pop_density_plot, male_plot, female_plot, p0_15_plot, p15_25_plot, p25_45_plot, p45_65_plot, p65_plot, labels = "AUTO")

plot_grid(p_adults_plot, p_unmarried_plot, p_married_plot, p_divorced_plot, p_widow_plot, p_western_imm_plot, p_not_western_imm_plot, n_company_plot, avg_house_plot, labels = "AUTO")

plot_grid(n_working_plot, avg_income_plot, p_low_income_plot, p_high_income_plot, p_aow_plot, p_uitkering_plot, d_supermarked_plot, d_highschool_plot, d_NN_voting_station_plot, labels = "AUTO")

```

```{r}
# Map the dependent variable turnout
turnout_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "turnout_ratio", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,0.2,0.4,0.6,0.8,1,1.5,2)) 

# Map interesting independent variables to compare with the spatial distribution of the independent variable 
pop_density_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "bev_dichth_km2", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,250,500,750,1000,2500,5000,10000))

male_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "man", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.3,0.4,0.5,0.6,0.7,1.0))

female_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "vrouw", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.3,0.4,0.5,0.6,0.7,1.0))

age_0_15_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_0_15_jaar", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

age_15_25_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_15_25_jaar", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

age_25_45_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_25_45_jaar", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

age_45_65_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_45_65_jaar", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

age_65_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_65_jaar", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

age_adults_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_adults", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.3,0.4,0.5,0.6,0.7,1.0))

unmarried_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_ongehuwd", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.3,0.4,0.5,0.6,0.7,1.0))

married_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_gehuwd", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.3,0.4,0.5,0.6,0.7,1.0))

divorced_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_gescheiden", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

widow_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_verweduwd", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

western_imm_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_ia_west", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

not_western_imm_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_ia_n_west", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

company_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "aantal_bedrijf", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,250,500,750,1000,2500,5000,10000))

house_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "gem_woning_waarde", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,150,200,250,300,400,600,1000))

p_income_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "aant_ink_ont", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,0.25,0.5,0.75,1.0,1.25,1.5,2))

income_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "gem_ink_p_o", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,20,25,30,35,40,50,100))

low_income_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_laag_ink", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,0.2,0.3,0.4,0.5,0.6,0.7,1.0))

high_income_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "p_hoog_ink", 
                                col.regions=brewer.pal(9, "YlOrRd"),
                                at = c(0,0.2,0.3,0.4,0.5,0.6,0.7,1.0))

aow_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "aow_uitk", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

supermarket_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "afst_levensm_5km", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,20,40,60,80,100,250))

highschool_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "voortg_ond_3km", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,20,40,60,80,100,250))

uitkering_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "tot_uitkering", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,0.1,0.2,0.3,0.4,0.5,1.0))

d_NN_voting_station_map <- mapview::mapview(neighbourhood_data, 
                                zcol = "dist_NN_voting_station", 
                                col.regions=brewer.pal(8, "YlOrRd"),
                                at = c(0,250,500,750,1000,2000,5000))
```

```{r}
# Display two maps with a slider to compare the spatial distribution of the variables in all the neighborhoods
turnout_map

pop_density_map

male_map

female_map

age_0_15_map

age_15_25_map

age_25_45_map

age_45_65_map

age_65_map

age_adults_map

unmarried_map

married_map

divorced_map
```

```{r}
widow_map

western_imm_map

not_western_imm_map

company_map

house_map

p_income_map

income_map

low_income_map

high_income_map

aow_map

uitkering_map

supermarket_map

highschool_map

d_NN_voting_station_map
```

```{r}
# Plot the neighbourhoods of original data (ones with water already removed)
plot(neighbourhood_data$geometry) 
```

```{r}
# Drop variables that aren't relevant, e.g. due to multicollinearity with another variable or due to many missing values (which can't be reliably imputed) 
# Drop aantal_inw and n_turnout because it aren't ratios (used to compute these instead), gem_ink_p_o due to almost 50% missing values (and high correlation with p_laag_ink and p_hoog_ink), man due to high correlation with vrouw as CBS assumes binary sex
# Further, due to multicollinearity (high VIF after running linear regression sequentially after dropping another high VIF variable: done in another R notebook) drop the following predictors: p_verweduwd, p_ongehuwd, p_gehuwd (correlation maybe with an age group), afst_levensm_5km (correlation maybe with population density), p_hoog_ink (insignificant in lm and correlation maybe with gem_woning_waarde), p_adults (correlation with other age groups), p_aow (correlation with 65+ age group and hence with other age groups), p_65_jaar (correlation probably with other age groups because when it isn't one of the others, then will be this one), tot_uitkering (correlation maybe with low income)
neighbourhood_data <- subset(neighbourhood_data, select=-c(aantal_inw, n_turnout, gem_ink_p_o, man, p_verweduwd, p_ongehuwd, p_gehuwd, afst_levensm_5km, p_hoog_ink, p_adults, aow_uitk, p_65_jaar, tot_uitkering))

# Set a maximum value for variables to tackle outliers for more robust training
# This is based on the density plots
neighbourhood_data$turnout_ratio <- ifelse(neighbourhood_data$turnout_ratio<=1, neighbourhood_data$turnout_ratio, 1)
neighbourhood_data$bev_dichth_km2 <- ifelse(neighbourhood_data$bev_dichth_km2<=7500, neighbourhood_data$bev_dichth_km2, 7500)
neighbourhood_data$vrouw <- ifelse(neighbourhood_data$vrouw<=0.6, neighbourhood_data$vrouw, 0.6)
neighbourhood_data$p_0_15_jaar <- ifelse(neighbourhood_data$p_0_15_jaar<=0.3, neighbourhood_data$p_0_15_jaar, 0.3)
neighbourhood_data$p_15_25_jaar <- ifelse(neighbourhood_data$p_15_25_jaar<=0.3, neighbourhood_data$p_15_25_jaar, 0.3)
neighbourhood_data$p_25_45_jaar <- ifelse(neighbourhood_data$p_25_45_jaar<=0.4, neighbourhood_data$p_25_45_jaar, 0.4)
neighbourhood_data$p_45_65_jaar <- ifelse(neighbourhood_data$p_45_65_jaar<=0.4, neighbourhood_data$p_45_65_jaar, 0.4)
neighbourhood_data$p_gescheiden <- ifelse(neighbourhood_data$p_gescheiden<=0.2, neighbourhood_data$p_gescheiden, 0.2)
neighbourhood_data$p_ia_west <- ifelse(neighbourhood_data$p_ia_west<=0.2, neighbourhood_data$p_ia_west, 0.2)
neighbourhood_data$p_ia_n_west <- ifelse(neighbourhood_data$p_ia_n_west<=0.2, neighbourhood_data$p_ia_n_west, 0.2)
neighbourhood_data$aantal_bedrijf <- ifelse(neighbourhood_data$aantal_bedrijf<=2000, neighbourhood_data$aantal_bedrijf, 2000)
neighbourhood_data$gem_woning_waarde <- ifelse(neighbourhood_data$gem_woning_waarde<=500, neighbourhood_data$gem_woning_waarde, 500)
neighbourhood_data$aant_ink_ont <- ifelse(neighbourhood_data$aant_ink_ont<=1,neighbourhood_data$aant_ink_ont, 1)
neighbourhood_data$p_laag_ink <- ifelse(neighbourhood_data$p_laag_ink<=0.6, neighbourhood_data$p_laag_ink, 0.6)
neighbourhood_data$voortg_ond_3km <- ifelse(neighbourhood_data$voortg_ond_3km<=30, neighbourhood_data$voortg_ond_3km, 30)
neighbourhood_data$dist_NN_voting_station <- ifelse(neighbourhood_data$dist_NN_voting_station<=2500, neighbourhood_data$dist_NN_voting_station, 2500)

# Drop rows that contain one or multiple NA value(s) because otherwise the models can't be trained (e.g. neighbourhoods in which wasn't voted due to no municipal elections, or no polling station there, or missing value in a predictor variable which would be biased when imputed) 
neighbourhood_data <- na.omit(neighbourhood_data)
```

```{r}
print(paste("There are ", nrow(neighbourhood_data), " neighbourhoods in the dataset after the ones with missing values were removed"))
```

```{r}
# Show data preview
neighbourhood_data 
```

```{r}
# Plot the neighbourhoods which will be used for analysis
plot(neighbourhood_data$geometry) 
```

## Pre-process data
Pre-process the data by creating a training and test dataset, normalizing the variables, and creating a model recipe with the model equation. Additionally,  cross validation splits will be created with one taking into account spatial coordinates and the other one not, to check for difference in tuned parameters and model performance.

```{r}
# Set seed for reproducible results
set.seed(123)

# Determine coordinates of neighbourhood centroids to split on with spatial cross validation
centroid_coords <- st_coordinates(st_centroid(neighbourhood_data$geometry))
# Need to get integers instead of doubles, and add to dataframe
neighbourhood_data$X_centroid <- centroid_coords[,c("X")]
neighbourhood_data$Y_centroid <- centroid_coords[,c("Y")] 

# Split the data into a training (75%) and test (25%) set using stratification on the dependent variable (turnout) to have a representative test sample
data_split <- rsample::initial_split(neighbourhood_data, strata = "turnout_ratio", prop = 0.75)
train_data <- rsample::training(data_split)
test_data  <- rsample::testing(data_split)

# Declare the set explicit
train.set <- train_data
test.set <- test_data
```

```{r}
# For the training dataset, create cross validation splits
# Create split without spatial cross-validation, but consider the dependent variable on which to stratify. Here the number of samples per fold is relatively equal, whereas with spatial cross-validation this is less the case
cv_splits <- rsample::vfold_cv(train.set, strata = "turnout_ratio", k = 10) #here K is the number of fold, k=10 is ten fold CV
print(cv_splits)
```

```{r}
# Create split with spatial cross-validation by clustering coordinate information
cv_spatial_folds <- spatial_clustering_cv(data.frame(train.set), coords = c("X_centroid", "Y_centroid"), v = 10)
print (cv_spatial_folds) 
```

Now the data is ready, the model recipe is defined.
```{r}
# Set the equation of the model recipe for predicting the dependent variable turnout
# Socio-economic variables
model_eq_economic <- turnout_ratio ~ gem_woning_waarde + aant_ink_ont + p_laag_ink 

# Socio-demographic variables
model_eq_demographic <- turnout_ratio ~ vrouw + p_0_15_jaar + p_15_25_jaar + p_25_45_jaar + p_45_65_jaar + p_gescheiden + p_ia_west + p_ia_n_west

# Spatial location variables
model_eq_location <- turnout_ratio ~ bev_dichth_km2 + aantal_bedrijf + voortg_ond_3km + dist_NN_voting_station

# Composite of most promising variables 
model_eq_final <- turnout_ratio ~ bev_dichth_km2 + vrouw + p_0_15_jaar + p_15_25_jaar + p_25_45_jaar + p_45_65_jaar + p_gescheiden + p_ia_west + p_ia_n_west + aantal_bedrijf + gem_woning_waarde + aant_ink_ont + p_laag_ink + voortg_ond_3km + dist_NN_voting_station
```

```{r}
#' Create tidymodels model recipe from equation and include training dataset. This function also normalizes, centralizes, and scales the predictor variables, and inspects the final recipe
#' 
#' @param model_eq formula of the model that has to be trained
#' @param training_data training dataset that will be used for fitting the models
#' 
#' @return model_rec final tidymodels model recipe
create_recipe <- function(model_eq, training_data){
  model_rec <- recipe(model_eq, data = training_data) %>%
    # Normalize the predictor variables using z-normalization
    step_zv(all_predictors()) %>%
    # Centralize some predictors 
    step_center(all_predictors()) %>%
    # Scale predictors with large values 
    step_scale(all_predictors())
  
  # Inspect the final recipe by first preparing and then juicing it using glimpse, which shows the model structure for some samples
  glimpse(model_rec %>% prep() %>% juice())
  
  return (model_rec)
}
```

```{r}
# Create model recipes
# Socio-economic variables
model_rec_economic <- create_recipe(model_eq=model_eq_economic, training_data=train.set)

# Socio-demographic variables
model_rec_demographic <- create_recipe(model_eq=model_eq_demographic, training_data=train.set)

# Spatial location variables
model_rec_location <- create_recipe(model_eq=model_eq_location, training_data=train.set)

# Composite of most promising variables
model_rec_final <- create_recipe(model_eq=model_eq_final, training_data=train.set)
```
## Train Geographically weighted regression model
Train Geographically weighted regression model with adaptive kernel using each of the described functions from above. For this need to take all data instead of only training data because the learned formula for one neighbourhood is not generalisable to other neighbourhoods.

```{r}
#' Train Geographically Weighted Regression (GWR) model with an adaptive kernel.
#' This can't be done using the tidymodels package like the Linear regression and Random forest will use afterwards
#'
#' @param data Dataset with observations to fit
#' @param model_equation formula of the model that has to be trained
#' @param weight_func gwr weight function to use for the adaptive kernel (default gwr.Gauss, but other option is for example gwr.bisquare)
#' @param bandwidth the fraction of neighbourhoods to consider for an adaptive kernel (default NULL: an optimal value will be determined using cross validation)
#' 
#' @return (gwr_model, k_NN) the trained GWR model and the number of nearest neighbourhoods to consider in the adaptive kernel
train_GWR <- function(data, model_equation, weight_func=gwr.Gauss, bandwidth=NULL){
  # Before doing analysis for GWR the sf polygon object must be converted into a sp spatial object because the spgwr package usually works on sp objects 
  data <- as_Spatial(data)
  
  # Select optimal bandwidth for adaptive kernel (so k nearest neighbourhoods)
  if (is.null(bandwidth)){
    bandwidth <- gwr.sel(model_equation, 
                data = data,
                longlat = TRUE, 
                adapt = TRUE, 
                gweight = weight_func) 
  }
  
  # Determine number nearest neighbourhood observations to include 
  k_NN <- bandwidth * nrow(data)
  print(paste("Adaptive kernel with number of nearest neighbourhoods: ", k_NN, " of total number of neighbourhoods: ", nrow(data)))
  
  # Train Geographically weighted regression model
  gwr_model <- gwr(model_equation, data = data,
                   longlat = TRUE, gweight = weight_func, hatmatrix=TRUE, se.fit=TRUE, adapt=bandwidth)
  
  # Show summary of Geographically weighted regression model
  gwr_model
  
  return (gwr_model)
}
```

```{r}
# Train model for each equation using different weight functions
# Final formula with all predictors that don't have multicollinearity
# Train this with Gaussian and Bisquare kernel shape
gwr_final_gauss <- train_GWR(data=neighbourhood_data, model_equation=model_eq_final, weight_func=gwr.Gauss, bandwidth=NULL)
gwr_final_bisquare <- train_GWR(data=neighbourhood_data, model_equation=model_eq_final, weight_func=gwr.bisquare, bandwidth=NULL)
```

```{r}
# Socio-economic
# gwr_economic_gauss <- train_GWR(data=neighbourhood_data, model_equation=model_eq_economic, weight_func=gwr.Gauss, bandwidth=NULL)
gwr_economic_bisquare <- train_GWR(data=neighbourhood_data, model_equation=model_eq_economic, weight_func=gwr.bisquare, bandwidth=NULL)
```

```{r}
# Socio-demographic
# gwr_demographic_gauss <- train_GWR(data=neighbourhood_data, model_equation=model_eq_demographic, weight_func=gwr.Gauss, bandwidth=NULL)
gwr_demographic_bisquare <- train_GWR(data=neighbourhood_data, model_equation=model_eq_demographic, weight_func=gwr.bisquare, bandwidth=NULL)
```

```{r}
# Spatial location
# gwr_location_gauss <- train_GWR(data=neighbourhood_data, model_equation=model_eq_location, weight_func=gwr.Gauss, bandwidth=NULL)
gwr_location_bisquare <- train_GWR(data=neighbourhood_data, model_equation=model_eq_location, weight_func=gwr.bisquare, bandwidth=NULL)
```

## Set up workflows for training linear regression and random forest models
Create the model workflows which will be used for training and predicting different models using the recipe, and set up grid search with a cross validation process for hyperparameter tuning. This then results in the final, optimal models to employ. Below first the model plans are created for linear regression, geographically weighted regression, and random forest models.

```{r}
# Create the model plans, indicating which types of models to fit and what hyperparameters to tune

# Linear regression plan
lm_plan <- 
  linear_reg() %>% 
  set_engine("lm")

# Random forest plan
rf_plan <- parsnip::rand_forest() %>%
  parsnip::set_args(mtry  = tune()) %>%
  parsnip::set_args(min_n = tune()) %>%
  parsnip::set_args(trees = 2000) %>% # Setting the first search with 2000 trees 
  parsnip::set_engine("ranger", importance = "permutation") %>% 
  parsnip::set_mode("regression")
```

For the hyperparameters that are set to be tuned above, set up the grid search combinations to use for tuning. 
```{r}
# Use the expansion option for setting the grids
# Random forest grid
rf_grid <- expand.grid (mtry = c(3,6,9), 
                       min_n = c(100,500,800))
```

## Determine the best tuned hyperparameters and corresponding linear regression and random forest models
Now we can create the workflow for training the models to match the model recipe with the model plans. The created workflows are then used to tune the models to their grids to be able to extract the optimal hyperparameters and their corresponding models. This is done using the cross validation datasets. Extract the best hyperparameters from each above tuned models and their corresponding optimal models based on their training performance.

```{r}
#' Determine the best parameters for linear regression model using (spatial) cross validation with the training dataset, and make predictions on the validation set
#' 
#' @param lm_plan tidymodels plan of linear regression model which specifies the kind of model to train
#' @param model_recipe tidymodels recipe describing the equation to determine relations for
#' @param cv_folds (spatial) cross validation folds on the training dataset
#' 
#' @retun list(lm_best_params, lm_best_OOF_preds, lm_best_wf) where the first element contains the best coefficients for the linear regression model, the second element the predictions on the validation set based on the best model corresponding to these coefficients, and the third element the final workflow to be used for training on the full training dataset
lm_cross_validation <- function(lm_plan, model_recipe, cv_folds){
  # Set model workflows
  lm_wf <-
    workflows::workflow() %>% 
    add_recipe(model_recipe) %>% 
    add_model(lm_plan)
  
  # Tune linear regression coefficients (no hyperparameters to tune, but recipe coefficients instead; grid value states how many coefficient combinations need to be created automatically)
  lm_tuned <- tune_grid(lm_wf, resamples = cv_folds, grid = 10, control=control_grid(save_pred = TRUE))
  
  # Extract the best parameters based on RMSE, also used for evaluating performance on the test data
  lm_best_params <- select_best(lm_tuned, metric = "rmse")
  
  # Pull best hyperparameter combination from the 10-fold cross validated predictions
  lm_best_OOF_preds <- collect_predictions(lm_tuned)
  
  # Retrieve the best parameter model
  lm_best_OOF_preds <- lm_best_OOF_preds %>% dplyr::select(-id,-.config)
  
  # Create final workflow, used for the final training round on the full training dataset
  lm_best_wf <- finalize_workflow(lm_wf, lm_best_params)
  
  return (list(lm_best_params, lm_best_OOF_preds, lm_best_wf))
}
```

```{r}
# Use cross validation to determine the best linear regression model
# Composite of all most promising variables
lm_lst_final <- lm_cross_validation(lm_plan=lm_plan, model_recipe=model_rec_final, cv_folds=cv_splits)

lm_best_params_final <- lm_lst_final[[1]]
lm_best_OOF_preds_final <- lm_lst_final[[2]]
lm_best_wf_final <- lm_lst_final[[3]]
```

```{r}
# Use spatial cross validation to determine the best linear regression model
# Composite of all most promising variables
lm_lst_spatial_final <- lm_cross_validation(lm_plan=lm_plan, model_recipe=model_rec_final, cv_folds=cv_spatial_folds)

lm_best_params_spatial_final <- lm_lst_spatial_final[[1]]
lm_best_OOF_preds_spatial_final <- lm_lst_spatial_final[[2]]
lm_best_wf_spatial_final <- lm_lst_spatial_final[[3]]
```

```{r}
# Use spatial cross validation to determine the best linear regression model
# Socio-economic
lm_lst_spatial_economic <- lm_cross_validation(lm_plan=lm_plan, model_recipe=model_rec_economic, cv_folds=cv_spatial_folds)

lm_best_params_spatial_economic <- lm_lst_spatial_economic[[1]]
lm_best_OOF_preds_spatial_economic <- lm_lst_spatial_economic[[2]]
lm_best_wf_spatial_economic <- lm_lst_spatial_economic[[3]]
```

```{r}
# Use spatial cross validation to determine the best linear regression model
# Socio-demographic
lm_lst_spatial_demographic <- lm_cross_validation(lm_plan=lm_plan, model_recipe=model_rec_demographic, cv_folds=cv_spatial_folds)

lm_best_params_spatial_demographic <- lm_lst_spatial_demographic[[1]]
lm_best_OOF_preds_spatial_demographic <- lm_lst_spatial_demographic[[2]]
lm_best_wf_spatial_demographic <- lm_lst_spatial_demographic[[3]]
```

```{r}
# Use spatial cross validation to determine the best linear regression model
# Spatial location
lm_lst_spatial_location <- lm_cross_validation(lm_plan=lm_plan, model_recipe=model_rec_location, cv_folds=cv_spatial_folds)

lm_best_params_spatial_location <- lm_lst_spatial_location[[1]]
lm_best_OOF_preds_spatial_location <- lm_lst_spatial_location[[2]]
lm_best_wf_spatial_location <- lm_lst_spatial_location[[3]]
```

```{r}
#' Determine the best hyperparameters for random forest model using (spatial) cross validation with the training dataset, and make predictions on the validation set
#' 
#' @param rf_plan tidymodels plan of random forest model which specifies the kind of model to train
#' @param rf_grid tidymodels grid with the hyperparameter value combinations to determine the best ones of using cross validation
#' @param model_recipe tidymodels recipe describing the equation to determine relations for
#' @param cv_folds (spatial) cross validation folds on the training dataset
#' 
#' @retun list(rf_best_params, rf_best_OOF_preds, rf_best_wf) where the first element contains the best hyperparameters for the random forest model, the second element the predictions on the validation set based on the best model corresponding to these parameters, and the third element the final workflow to be used for training on the full training dataset
rf_cross_validation <- function(rf_plan, rf_grid, model_recipe, cv_folds){
  # Set model workflows
  rf_wf <-
  workflows::workflow() %>% 
  add_recipe(model_recipe) %>% 
  add_model(rf_plan)
  
  # Tune model hyperparameters
  rf_tuned <- tune_grid(rf_wf, resamples = cv_folds, grid = rf_grid, control=control_grid(save_pred = TRUE))
  
  # Extract the best parameters based on RMSE, also used for evaluating performance on the test data
  rf_best_params <- select_best(rf_tuned, metric = "rmse")
  
  # Pull best hyperparameter combinations from the 10-fold cross validated predictions
  rf_best_OOF_preds <- collect_predictions(rf_tuned) %>%
    filter(mtry  == rf_best_params$mtry[1] & min_n == rf_best_params$min_n[1])
  
  # Retrieve the best parameter models
  rf_best_OOF_preds <- rf_best_OOF_preds %>% dplyr::select(-id,-.config)
  
  # Create final workflow
  rf_best_wf <- finalize_workflow(rf_wf, rf_best_params)
  
  return (list(rf_best_params, rf_best_OOF_preds, rf_best_wf))
}
```

```{r}
# Use cross validation to determine the best random forest model
# Composite of most promising variables
rf_lst_final <- rf_cross_validation(rf_plan=rf_plan, rf_grid=rf_grid, model_recipe=model_rec_final, cv_folds=cv_splits)

rf_best_params_final <- rf_lst_final[[1]]
rf_best_OOF_preds_final <- rf_lst_final[[2]]
rf_best_wf_final <- rf_lst_final[[3]]
```

```{r}
# Use spatial cross validation to determine the best random forest model
# Composite of most promising variables
rf_lst_spatial_final <- rf_cross_validation(rf_plan=rf_plan, rf_grid=rf_grid, model_recipe=model_rec_final, cv_folds=cv_spatial_folds)

rf_best_params_spatial_final <- rf_lst_spatial_final[[1]]
rf_best_OOF_preds_spatial_final <- rf_lst_spatial_final[[2]]
rf_best_wf_spatial_final <- rf_lst_spatial_final[[3]]
```

```{r}
# Use spatial cross validation to determine the best random forest model
# Socio-economic
rf_lst_spatial_economic <- rf_cross_validation(rf_plan=rf_plan, rf_grid=rf_grid, model_recipe=model_rec_economic, cv_folds=cv_spatial_folds)

rf_best_params_spatial_economic <- rf_lst_spatial_economic[[1]]
rf_best_OOF_preds_spatial_economic <- rf_lst_spatial_economic[[2]]
rf_best_wf_spatial_economic <- rf_lst_spatial_economic[[3]]
```

```{r}
# Use spatial cross validation to determine the best random forest model
# Socio-demographic
rf_lst_spatial_demographic <- rf_cross_validation(rf_plan=rf_plan, rf_grid=rf_grid, model_recipe=model_rec_demographic, cv_folds=cv_spatial_folds)

rf_best_params_spatial_demographic <- rf_lst_spatial_demographic[[1]]
rf_best_OOF_preds_spatial_demographic <- rf_lst_spatial_demographic[[2]]
rf_best_wf_spatial_demographic <- rf_lst_spatial_demographic[[3]]
```

```{r}
# Use spatial cross validation to determine the best random forest model
# Spatial location
rf_lst_spatial_location <- rf_cross_validation(rf_plan=rf_plan, rf_grid=rf_grid, model_recipe=model_rec_location, cv_folds=cv_spatial_folds)

rf_best_params_spatial_location <- rf_lst_spatial_location[[1]]
rf_best_OOF_preds_spatial_location <- rf_lst_spatial_location[[2]]
rf_best_wf_spatial_location <- rf_lst_spatial_location[[3]]
```

Evaluate performance of these best tuned models on training data.
```{r}
# Make prediction for each model and attach error statistics
OOF_preds <- rbind(
  data.frame(lm_best_OOF_preds_final %>% dplyr::select(.pred,turnout_ratio),model = "Model-1a_Linear Regression final"),
                   data.frame(lm_best_OOF_preds_spatial_final %>% dplyr::select(.pred,turnout_ratio),model = "Model-1b_Linear Regression spatial final"),
  data.frame(lm_best_OOF_preds_spatial_economic %>% dplyr::select(.pred,turnout_ratio),model = "Model-1c_Linear Regression spatial economic"),
  data.frame(lm_best_OOF_preds_spatial_demographic %>% dplyr::select(.pred,turnout_ratio),model = "Model-1d_Linear Regression spatial demographic"),
  data.frame(lm_best_OOF_preds_spatial_location %>% dplyr::select(.pred,turnout_ratio),model = "Model-1e_Linear Regression spatial location"),
                   data.frame(rf_best_OOF_preds_final %>% dplyr::select(.pred,turnout_ratio),model = "Model-2a_Random Forest final"), 
                   data.frame(rf_best_OOF_preds_spatial_final %>% dplyr::select(.pred,turnout_ratio),model = "Model-2b_Random Forest spatial final"),
  data.frame(rf_best_OOF_preds_spatial_economic %>% dplyr::select(.pred,turnout_ratio),model = "Model-2c_Random Forest spatial economic"),
  data.frame(rf_best_OOF_preds_spatial_demographic %>% dplyr::select(.pred,turnout_ratio),model = "Model-2d_Random Forest spatial demographic"),
  data.frame(rf_best_OOF_preds_spatial_location %>% dplyr::select(.pred,turnout_ratio),model = "Model-2e_Random Forest spatial location")) %>%
  group_by(model) %>% 
  mutate(
    RMSE = yardstick::rmse_vec(turnout_ratio, .pred),
    MAE  = yardstick::mae_vec(turnout_ratio, .pred),
    MAPE = yardstick::mape_vec((turnout_ratio+1), (.pred+1))) %>% 
  ungroup()
```

```{r}
# Plot average squared error (RMSE) for each model 
ggplot(data = OOF_preds %>%
         dplyr::select(model, RMSE) %>%
         distinct() ,
       aes(x = model, y = RMSE, group = 1)) +
  geom_path(color = "green") +
  geom_label(aes(label = round(RMSE,3))) +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Plot mean absolute error (MAE) for each model
ggplot(data = OOF_preds %>%
         dplyr::select(model, MAE) %>%
         distinct() ,
       aes(x = model, y = MAE, group = 1))  +
  geom_path(color = "red") +
  geom_label(aes(label = round(MAE,3))) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Plot predicted versus the observed values for each model in scatter plots
ggplot(OOF_preds, aes(y=.pred , x = turnout_ratio,group = model)) + 
  geom_point(alpha = 0.3) +
  coord_equal() +
  geom_abline(linetype = "dashed",color = "blue") +
  geom_smooth(method="lm", color = "red") +
  facet_wrap(~model,ncol = 3)+
  theme_bw()+
  xlab("Election turnout fraction") + 
  ylim(0, 10)+
  xlim(0, 10)
```

As can be seen, the different models predict differently and have varying level of training errors.

## Evaluate linear regression and random forest models on test data
To check how well the models generalise to unseen data, the predictions are made for the test data and corresponding errors are determined. For this the models with best parameters are first fit with the full training dataset and not only cross validation folds.

```{r}
#' Fit a final linear regression model based on the best coefficients and full training dataset and determine its predictions on the test dataset
#' 
#' @param lm_workflow the workflow of the linear regression model with the best coefficients and recipe
#' @param data_split a split into training and test dataset, respectively for training and prediction purposes 
#' 
#' @return list(lm_val_fit_geo, lm_val_pred_geo) list with as first element the final fit linear regression model, and as second element its predictions on the test dataset
lm_final_training <- function(lm_workflow, data_split){
  # Fit model on full training dataset
  lm_val_fit_geo <- lm_workflow %>%
    last_fit(split     = data_split,
           metrics   = metric_set(yardstick::rmse, yardstick::rsq))
  
  # Using this final trained model, make predictions for the test dataset and get the best configuration for the test data for required model
  lm_val_pred_geo <- collect_predictions(lm_val_fit_geo)
  
  return (list(lm_val_fit_geo, lm_val_pred_geo))
}
```

```{r}
# Fit and test a final linear regression model for which its coefficients were determined without spatial cross validation
# Composite of best predictor variables
lm_fit_lst_final <- lm_final_training(lm_workflow=lm_best_wf_final, data_split=data_split)

lm_val_fit_geo_final <- lm_fit_lst_final[[1]]
lm_val_pred_geo_final <- lm_fit_lst_final[[2]]
```

```{r}
# Fit and test a final linear regression model for which its coefficients were determined with spatial cross validation
# Composite of best predictor variables
lm_fit_lst_spatial_final <- lm_final_training(lm_workflow=lm_best_wf_spatial_final, data_split=data_split)

lm_val_fit_geo_spatial_final <- lm_fit_lst_spatial_final[[1]]
lm_val_pred_geo_spatial_final <- lm_fit_lst_spatial_final[[2]]
```

```{r}
# Fit and test a final linear regression model for which its coefficients were determined with spatial cross validation
# Socio-economic
lm_fit_lst_spatial_economic <- lm_final_training(lm_workflow=lm_best_wf_spatial_economic, data_split=data_split)

lm_val_fit_geo_spatial_economic <- lm_fit_lst_spatial_economic[[1]]
lm_val_pred_geo_spatial_economic <- lm_fit_lst_spatial_economic[[2]]
```

```{r}
# Fit and test a final linear regression model for which its coefficients were determined with spatial cross validation
# Socio-demographic
lm_fit_lst_spatial_demographic <- lm_final_training(lm_workflow=lm_best_wf_spatial_demographic, data_split=data_split)

lm_val_fit_geo_spatial_demographic <- lm_fit_lst_spatial_demographic[[1]]
lm_val_pred_geo_spatial_demographic <- lm_fit_lst_spatial_demographic[[2]]
```

```{r}
# Fit and test a final linear regression model for which its coefficients were determined with spatial cross validation
# Spatial location
lm_fit_lst_spatial_location <- lm_final_training(lm_workflow=lm_best_wf_spatial_location, data_split=data_split)

lm_val_fit_geo_spatial_location <- lm_fit_lst_spatial_location[[1]]
lm_val_pred_geo_spatial_location <- lm_fit_lst_spatial_location[[2]]
```

```{r}
#' Fit a final random forest model based on the best hyperparameters and full training dataset and determine its predictions on the test dataset
#' 
#' @param rf_workflow the workflow of the random forest model with the best hyperparameters and recipe
#' @param data_split a split into training and test dataset, respectively for training and prediction purposes 
#' 
#' @return list(rf_val_fit_geo, rf_val_pred_geo) list with as first element the final fit random forest model, and as second element its predictions on the test dataset
rf_final_training <- function(rf_workflow, data_split){
  # Fit model on full training dataset
  rf_val_fit_geo <- rf_workflow %>% 
    last_fit(split     = data_split,
           metrics   = metric_set(yardstick::rmse, yardstick::rsq))
  
  # Using this final trained model, make predictions for the test dataset and get the best configuration for the test data for required model
  rf_val_pred_geo <- collect_predictions(rf_val_fit_geo)
  rf_val_pred_geo <- rf_val_pred_geo %>% dplyr::select(-id,-.config)
  
  return (list(rf_val_fit_geo, rf_val_pred_geo))
}
```

```{r}
# Fit and test a final random forest model for which its hyperparameters were determined without spatial cross validation
# Composite of best predictors
rf_fit_lst_final <- rf_final_training(rf_workflow=rf_best_wf_final, data_split=data_split)

rf_val_fit_geo_final <- rf_fit_lst_final[[1]]
rf_val_pred_geo_final <- rf_fit_lst_final[[2]]
```

```{r}
# Fit and test a final random forest model for which its hyperparameters were determined with spatial cross validation
# Composite of best predictors
rf_fit_lst_spatial_final <- rf_final_training(rf_workflow=rf_best_wf_spatial_final, data_split=data_split)

rf_val_fit_geo_spatial_final <- rf_fit_lst_spatial_final[[1]]
rf_val_pred_geo_spatial_final <- rf_fit_lst_spatial_final[[2]]
```

```{r}
# Fit and test a final random forest model for which its hyperparameters were determined with spatial cross validation
# Socio-economic
rf_fit_lst_spatial_economic <- rf_final_training(rf_workflow=rf_best_wf_spatial_economic, data_split=data_split)

rf_val_fit_geo_spatial_economic <- rf_fit_lst_spatial_economic[[1]]
rf_val_pred_geo_spatial_economic <- rf_fit_lst_spatial_economic[[2]]
```

```{r}
# Fit and test a final random forest model for which its hyperparameters were determined with spatial cross validation
# Socio-demographic
rf_fit_lst_spatial_demographic <- rf_final_training(rf_workflow=rf_best_wf_spatial_demographic, data_split=data_split)

rf_val_fit_geo_spatial_demographic <- rf_fit_lst_spatial_demographic[[1]]
rf_val_pred_geo_spatial_demographic <- rf_fit_lst_spatial_demographic[[2]]
```

```{r}
# Fit and test a final random forest model for which its hyperparameters were determined with spatial cross validation
# Spatial location
rf_fit_lst_spatial_location <- rf_final_training(rf_workflow=rf_best_wf_spatial_location, data_split=data_split)

rf_val_fit_geo_spatial_location <- rf_fit_lst_spatial_location[[1]]
rf_val_pred_geo_spatial_location <- rf_fit_lst_spatial_location[[2]]
```

```{r}
# Aggregate test set predictions (these do not overlap with training prediction set, which is OOF_preds) with error statistics
val_preds <- rbind(
  data.frame(dplyr::select(lm_val_pred_geo_final, .pred, turnout_ratio), model = "Model-1a_Linear Regression final"),
                   data.frame(dplyr::select(lm_val_pred_geo_spatial_final, .pred, turnout_ratio), model = "Model-1b_Linear Regression spatial final"),
                     data.frame(dplyr::select(lm_val_pred_geo_spatial_economic, .pred, turnout_ratio), model = "Model-1c_Linear Regression spatial economic"),
                     data.frame(dplyr::select(lm_val_pred_geo_spatial_demographic, .pred, turnout_ratio), model = "Model-1d_Linear Regression spatial demographic"),
                     data.frame(dplyr::select(lm_val_pred_geo_spatial_location, .pred, turnout_ratio), model = "Model-1e_Linear Regression spatial location"),
                   data.frame(dplyr::select(rf_val_pred_geo_final, .pred, turnout_ratio), model = "Model-2a_Random Forest final"),
                   data.frame(dplyr::select(rf_val_pred_geo_spatial_final, .pred, turnout_ratio), model = "Model-2b_Random Forest spatial final"),
  data.frame(dplyr::select(rf_val_pred_geo_spatial_economic, .pred, turnout_ratio), model = "Model-2c_Random Forest spatial economic"),
  data.frame(dplyr::select(rf_val_pred_geo_spatial_demographic, .pred, turnout_ratio), model = "Model-2d_Random Forest spatial demographic"),
  data.frame(dplyr::select(rf_val_pred_geo_spatial_location, .pred, turnout_ratio), model = "Model-2e_Random Forest spatial location")) %>% 
  group_by(model) %>% 
  mutate(RMSE = yardstick::rmse_vec(turnout_ratio, .pred),
         MAE  = yardstick::mae_vec(turnout_ratio, .pred),
         MAPE = yardstick::mape_vec((turnout_ratio+1), (.pred+1)),
         absE=abs(turnout_ratio-.pred)) %>% 
  ungroup()
```

```{r}
# Plot average squared error (RMSE) for each model 
ggplot(data = val_preds %>% 
                           dplyr::select(model, RMSE) %>% 
                           distinct() , 
                         aes(x = model, y = RMSE, group = 1))  +
  geom_path(color = "green") +
  geom_label(aes(label = round(RMSE,4))) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Plot mean absolute error (MAE) for each model 
ggplot(data = val_preds %>%
         dplyr::select(model, MAE) %>%
         distinct() ,
       aes(x = model, y = MAE,group = 1))  +
  geom_path(color = "red") +
  geom_label(aes(label = round(MAE,3))) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Plot predicted versus the observed values for each model in scatter plots
ggplot(val_preds, aes(y=.pred , x = turnout_ratio,group = model))+ 
  geom_point(alpha = 0.3) +
  coord_equal() +
  geom_abline(linetype = "dashed",color = "red") +
  geom_smooth(method="lm", color = "blue") +
  facet_wrap(~model,ncol = 3)+
  theme_bw()+
  xlab("Election turnout fraction") + 
  ylim(0,10)+
  xlim(0,10)
```
As can be seen, like with the performance on training data, the different models predict differently and have varying level of testing errors.

## Check for spatial autocorrelation with linear regression model
Check if the assumptions of final trained linear regression model hold using this dataset (likely not), by investigating multicollinearity and spatial autocorrelation.

```{r}
# Check assumptions of linear regression like multicollinearity, which occurs when the predictor variables actually predict one another, and due to correlation some predictor variables may also be redundant
# Information from: https://jhudatascience.org/tidyversecourse/model.html 5.14.1.4 and https://cran.r-project.org/web/packages/performance/performance.pdf
# Composite of best predictors
lm_val_fit_geo_final %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>% check_model(panel=FALSE) # Without spatial cross validation
```

```{r} 
# Composite of best predictors
lm_val_fit_geo_spatial_final %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>% check_model(panel=FALSE) # With spatial cross validation
```

```{r} 
# Socio-economic
lm_val_fit_geo_spatial_economic %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>% check_model(panel=FALSE) # With spatial cross validation
```

```{r} 
# Socio-demographic
lm_val_fit_geo_spatial_demographic %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>% check_model(panel=FALSE) # With spatial cross validation
```

```{r} 
# Spatial location
lm_val_fit_geo_spatial_location %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>% check_model(panel=FALSE) # With spatial cross validation
```

```{r}
# Check multicollinearity with vif of car package
# Composite of best predictors
lm_model_final <- lm_val_fit_geo_final %>% pluck(".workflow", 1) %>% extract_fit_engine()
lm_model_final %>% car::vif() # Without spatial cross validation
```

```{r}
# Check multicollinearity with vif of car package
# Composite of best predictors
lm_model_spatial_final <- lm_val_fit_geo_spatial_final %>% pluck(".workflow", 1) %>% extract_fit_engine() 
lm_model_spatial_final %>% car::vif() # With spatial cross validation
```

```{r}
# Check multicollinearity with vif of car package
# Socio-economic
lm_model_spatial_economic <- lm_val_fit_geo_spatial_economic %>% pluck(".workflow", 1) %>% extract_fit_engine() 
lm_model_spatial_economic %>% car::vif() # With spatial cross validation
```

```{r}
# Check multicollinearity with vif of car package
# Socio-demographic
lm_model_spatial_demographic <- lm_val_fit_geo_spatial_demographic %>% pluck(".workflow", 1) %>% extract_fit_engine() 
lm_model_spatial_demographic %>% car::vif() # With spatial cross validation
```

```{r}
# Check multicollinearity with vif of car package
# Spatial location
lm_model_spatial_location <- lm_val_fit_geo_spatial_location %>% pluck(".workflow", 1) %>% extract_fit_engine() 
lm_model_spatial_location %>% car::vif() # With spatial cross validation
```

```{r}
# Inspect more model statistics 
# Without spatial cross validation
# Composite of best predictors
tidy(lm_model_final)
augment(lm_model_final)
glance(lm_model_final)
```

```{r}
# Inspect more model statistics 
# With spatial cross validation
# Composite of best predictors
tidy(lm_model_spatial_final)
augment(lm_model_spatial_final)
glance(lm_model_spatial_final)
```

```{r}
# Inspect more model statistics 
# With spatial cross validation
# Socio-economic
tidy(lm_model_spatial_economic)
augment(lm_model_spatial_economic)
glance(lm_model_spatial_economic)
```

```{r}
# Inspect more model statistics 
# With spatial cross validation
# Socio-demographic
tidy(lm_model_spatial_demographic)
augment(lm_model_spatial_demographic)
glance(lm_model_spatial_demographic)
```

```{r}
# Inspect more model statistics 
# With spatial cross validation
# Spatial location
tidy(lm_model_spatial_location)
augment(lm_model_spatial_location)
glance(lm_model_spatial_location)
```

```{r}
# Check for spatial autocorrelation by first creating different kinds of weight matrixes describing neighbourhood relations

# Adjacency matrix using Euclidean distance between neighbourhood centroids 
# Because not all neighbourhoods are touching each other (not all have a turnout value), queens contiguity matrix does not work (with poly2nb function)
neighbours <- dnearneigh(centroid_coords, 0, 50000) # Defining as adjacent all observations between 0 and 50km
Wadj = nb2listw(neighbours, style = "W", zero.policy = TRUE) # Computing weight matrix W; style W row normalized; B non-normalized; zero.policy = TRUE means that some observations may have no adjacent neighbourhoods

# Distance-based weight matrix W: 1/d (note that we're only calculating distance-based weight for "adjacent" nodes)
dist = nbdists(neighbours,centroid_coords) # Determine distance between all neighbourhood centroids
ids = lapply(dist, function(x) 1/(x+0.00001)) # Note that we add 0.00001 in the denominator to avoid divisions by zero, which would have occurred when a node is not considered to adjacent (thus giving 0 instead of NA as weight)
Wids = nb2listw(neighbours, glist = ids, style = "W", zero.policy = TRUE)

# Distance-based weight matrix W: 1/d^2
ids2 = lapply(dist, function(x) 1/(x^2+0.00001))
Wids2 = nb2listw(neighbours, glist = ids2, style = "W", zero.policy = TRUE)

# Distance-based weight matrix W: exp(-x)
expdis <- lapply(dist, function(x) {
  tryCatch(exp(-x/50000), error = function(e) return(NULL))
}) # Note that the exponential function is scale dependent, and consequentially the number used to normalize the distances (in this case 50km; equal to the maximum distance for adjacent units) affects W

Wexpdis = nb2listw(neighbours, glist = expdis, style = "W", zero.policy = TRUE)
```

```{r}
# Plot adjacent neighbours with line between them
coordsW <- neighbourhood_data %>%
  st_centroid()%>%
  st_geometry()
plot(Wadj, st_geometry(coordsW), col="red")
```

```{r}
# Show summary of neighbourhood adjacency
summary(Wadj, zero.policy=TRUE) 

# Print weights of first few neighbourhoods
# print(weights(Wadj)[1:5],zero.policy=TRUE)
```

```{r}
#' Check spatial autocorrelation with linear regression model and create plots of this
#' 
#' @param fit_model final fit of linear regression model
#' @param weight_matrix weight matrix stating the neighbourhood relations to take into account
#' @param dataset full neighbourhood dataset
#' @param n_permutations (default 1000) number of permutations for Monte Carlo method to bootstrap different polygon distribution
#' @param suffix (default '') suffix used for the column name with residuals of each neighbourhood (otherwise it may be overwritten when different linear regression models were trained and inspected with this function)
#' 
#' @return list(mc_global, lm_res) list with as first element the Moran's I, and as second element a map with the residuals plotted on the neighbourhoods
lm_check_autocorrelation <- function(fit_model, weight_matrix, dataset, test_data, training_data, test_predictions, n_permutations=1000, suffix=''){
  # Determine the residuals for the full dataset in the same order as the neighbourhoods in the weight matrix (not only for the training data as in fit_model$residuals (due to train-test split))
  # Compute the residuals of test data and match these with neighbourhood IDs
  test_residuals <- cbind(test_data$ID, test_predictions$turnout_ratio - test_predictions$.pred)
  # Match the residuals of training data with neighbourhood IDs
  training_residuals <- cbind(training_data$ID, fit_model$residuals)
  # Add the residuals dataframes together
  residuals <- rbind(test_residuals, training_residuals)
  # Add column names to residuals matrix
  colnames(residuals) <- c("ID", "residual")
  # Create dataframe out of residuals matrix
  residuals_df <- data.frame(residuals)
  # Sort the residuals based on the neighbourhood ID to get in the same order as the neighbourhoods in the weight matrix
  residuals_ordered <- residuals_df[order(residuals_df$ID),]
  
  # Because the moran.test function for retrieving the Moran's I is sensitive to irregularly distributed polygons, here we use a Monte Carlo method to bootstrap different polygon distribution (with moran.mc() function)
  mc_global <- moran.mc(residuals_ordered$residual, weight_matrix, n_permutations, alternative="greater")
  
  # Plot the  Moran's I
  plot(mc_global) 
  
  print(mc_global) # When the p value is significant we reject the null hypothesis that there is no significant autocorrelations among the variable, and accept that, the residual has spatial clustering
  
  # Plot the residual on the neighbourhood polygons
  col_str <- paste("res_lm", suffix, sep="_") # Create column name using suffix
  dataset[col_str] <- residuals_ordered$residual
  lm_res <- qtm(dataset, col_str)
  
  return (list(mc_global, lm_res))
}
```

```{r}
# Inspect spatial autocorrelation when linear regression coefficients were determined without spatial cross correlation, using adjacency matrix
# Composite of best predictors
lm_res_adj_lst_final <- lm_check_autocorrelation(fit_model=lm_model_final, weight_matrix=Wadj, dataset=neighbourhood_data, test_data=test.set, training_data=train.set, test_predictions=lm_val_pred_geo_final, n_permutations=1000, suffix='')
lm_res_adj_moran_final <- lm_res_adj_lst_final[[1]]
lm_res_adj_final <- lm_res_adj_lst_final[[2]]
```

```{r}
# Show residual plot using adjacency matrix and no spatial cross validation
lm_res_adj_final
```

```{r}
# Inspect spatial autocorrelation when linear regression coefficients were determined without spatial cross correlation, using inverse distance matrix
lm_res_ids_lst_final <- lm_check_autocorrelation(fit_model=lm_model_final, weight_matrix=Wids, dataset=neighbourhood_data, test_data=test.set, training_data=train.set, test_predictions=lm_val_pred_geo_final, n_permutations=1000, suffix='')
lm_res_ids_moran_final <- lm_res_ids_lst_final[[1]]
lm_res_ids_final <- lm_res_ids_lst_final[[2]]
```

```{r}
# Show residual plot using inverse distance matrix and no spatial cross validation
lm_res_ids_final
```

```{r}
# Inspect spatial autocorrelation when linear regression coefficients were determined without spatial cross correlation, using inverse distance squared matrix
lm_res_ids2_lst_final <- lm_check_autocorrelation(fit_model=lm_model_final, weight_matrix=Wids2, dataset=neighbourhood_data, test_data=test.set, training_data=train.set, test_predictions=lm_val_pred_geo_final, n_permutations=1000, suffix='')
lm_res_ids2_moran_final <- lm_res_ids2_lst_final[[1]]
lm_res_ids2_final <- lm_res_ids2_lst_final[[2]]
```

```{r}
# Show residual plot using inverse distance squared matrix and no spatial cross validation
lm_res_ids2_final
```

```{r}
# Inspect spatial autocorrelation when linear regression coefficients were determined without spatial cross correlation, using exp matrix
lm_res_expdis_lst_final <- lm_check_autocorrelation(fit_model=lm_model_final, weight_matrix=Wexpdis, dataset=neighbourhood_data, test_data=test.set, training_data=train.set, test_predictions=lm_val_pred_geo_final, n_permutations=1000, suffix='')
lm_res_expdis_moran_final <- lm_res_expdis_lst_final[[1]]
lm_res_expdis_final <- lm_res_expdis_lst_final[[2]]
```

```{r}
# Show residual plot using exp matrix and no spatial cross validation
lm_res_expdis_final
```

```{r}
# Inspect spatial autocorrelation when linear regression coefficients were determined with spatial cross correlation, using adjacency matrix
# Composite of best predictors
lm_res_adj_spatial_lst_final <- lm_check_autocorrelation(fit_model=lm_model_spatial_final, weight_matrix=Wadj, dataset=neighbourhood_data, test_data=test.set, training_data=train.set, test_predictions=lm_val_pred_geo_spatial_final, n_permutations=1000, suffix='spatial')
lm_res_adj_spatial_moran_final <- lm_res_adj_spatial_lst_final[[1]]
lm_res_adj_spatial_final <- lm_res_adj_spatial_lst_final[[2]]
```

```{r}
# Show residual plot using adjacency matrix and with spatial cross validation
lm_res_adj_spatial_final
```

```{r}
# Inspect spatial autocorrelation when linear regression coefficients were determined with spatial cross correlation, using inverse distance matrix
# Composite of best predictors
lm_res_ids_spatial_lst_final <- lm_check_autocorrelation(fit_model=lm_model_spatial_final, weight_matrix=Wids, dataset=neighbourhood_data, test_data=test.set, training_data=train.set, test_predictions=lm_val_pred_geo_spatial_final, n_permutations=1000, suffix='spatial')
lm_res_ids_spatial_moran_final <- lm_res_ids_spatial_lst_final[[1]]
lm_res_ids_spatial_final <- lm_res_ids_spatial_lst_final[[2]]
```

```{r}
# Show residual plot using inverse distance matrix and with spatial cross validation
lm_res_ids_spatial_final
```

```{r}
# Inspect spatial autocorrelation when linear regression coefficients were determined with spatial cross correlation, using inverse distance^2 matrix
# Composite of best predictors
lm_res_ids2_spatial_lst_final <- lm_check_autocorrelation(fit_model=lm_model_spatial_final, weight_matrix=Wids2, dataset=neighbourhood_data, test_data=test.set, training_data=train.set, test_predictions=lm_val_pred_geo_spatial_final, n_permutations=1000, suffix='spatial')
lm_res_ids2_spatial_moran_final <- lm_res_ids2_spatial_lst_final[[1]]
lm_res_ids2_spatial_final <- lm_res_ids2_spatial_lst_final[[2]]
```

```{r}
# Show residual plot using inverse distance^2 matrix and with spatial cross validation
lm_res_ids2_spatial_final
```

```{r}
# Inspect spatial autocorrelation when linear regression coefficients were determined with spatial cross correlation, using exp matrix
# Composite of best predictors
lm_res_expdis_spatial_lst_final <- lm_check_autocorrelation(fit_model=lm_model_spatial_final, weight_matrix=Wexpdis, dataset=neighbourhood_data, test_data=test.set, training_data=train.set, test_predictions=lm_val_pred_geo_spatial_final, n_permutations=1000, suffix='spatial')
lm_res_expdis_spatial_moran_final <- lm_res_expdis_spatial_lst_final[[1]]
lm_res_expdis_spatial_final <- lm_res_expdis_spatial_lst_final[[2]]
```

```{r}
# Show residual plot using exp matrix and with spatial cross validation
lm_res_expdis_spatial_final
```

```{r}
# Inspect spatial autocorrelation when linear regression coefficients were determined with spatial cross correlation, using inverse distance matrix
# Socio-economic
lm_res_ids_spatial_lst_economic <- lm_check_autocorrelation(fit_model=lm_model_spatial_economic, weight_matrix=Wids, dataset=neighbourhood_data, test_data=test.set, training_data=train.set, test_predictions=lm_val_pred_geo_spatial_economic, n_permutations=1000, suffix='spatial')
lm_res_ids_spatial_moran_economic <- lm_res_ids_spatial_lst_economic[[1]]
lm_res_ids_spatial_economic <- lm_res_ids_spatial_lst_economic[[2]]
```

```{r}
# Show residual plot using inverse distance matrix and with spatial cross validation
lm_res_ids_spatial_economic
```

```{r}
# Inspect spatial autocorrelation when linear regression coefficients were determined with spatial cross correlation, using inverse distance matrix
# Socio-demographic
lm_res_ids_spatial_lst_demographic <- lm_check_autocorrelation(fit_model=lm_model_spatial_demographic, weight_matrix=Wids, dataset=neighbourhood_data, test_data=test.set, training_data=train.set, test_predictions=lm_val_pred_geo_spatial_demographic, n_permutations=1000, suffix='spatial')
lm_res_ids_spatial_moran_demographic <- lm_res_ids_spatial_lst_demographic[[1]]
lm_res_ids_spatial_demographic <- lm_res_ids_spatial_lst_demographic[[2]]
```

```{r}
# Show residual plot using inverse distance matrix and with spatial cross validation
lm_res_ids_spatial_demographic
```

```{r}
# Inspect spatial autocorrelation when linear regression coefficients were determined with spatial cross correlation, using inverse distance matrix
# Spatial location
lm_res_ids_spatial_lst_location <- lm_check_autocorrelation(fit_model=lm_model_spatial_location, weight_matrix=Wids, dataset=neighbourhood_data, test_data=test.set, training_data=train.set, test_predictions=lm_val_pred_geo_spatial_location, n_permutations=1000, suffix='spatial')
lm_res_ids_spatial_moran_location <- lm_res_ids_spatial_lst_location[[1]]
lm_res_ids_spatial_location <- lm_res_ids_spatial_lst_location[[2]]
```

```{r}
# Show residual plot using inverse distance matrix and with spatial cross validation
lm_res_ids_spatial_location
```

For both linear regression models that are trained on a cross validation split with and without taking the spatial nature of the dataset into account, and for different weight matrices, significant spatial autocorrelation in the data can be concluded.

## Testing spatial lag and error models 
Using the weight matrices defined in the previous section, try to tackle spatial autocorrelation using spatial lag and error models. These don't take into account spatial non-stationarity, which will be accounted for in a Geographically weighted regression model.

```{r}
#' Estimate a Spatial error or lag model using a pre-defined weight matrix, and determine the spatial autocorrelation using Monte Carlo method for Moran's Index
#' 
#' @param model_equation formula of the model that has to be trained
#' @param data dataset with observations to fit
#' @param weight_matrix weight matrix defining neighbourhood relations
#' @param model_str string stating if a spatial error model ('error', the default value) should be trained or a spatial lag model ('lag')
#' @param n_permutations (default 1000) number of permutations for Monte Carlo method to bootstrap different polygon distribution
#' @param suffix (default '') suffix used for the column name with residuals of each neighbourhood (otherwise it may be overwritten when different spatial error models were trained and inspected with this function)
#' 
#' @return list(error_model, mc_global, error_res) list with as first element the trained spatial error model, as second element the Moran's I, and as third element a map with the residuals plotted on their neighbourhoods
estimate_error_lag_model <- function(model_equation, data, weight_matrix, model_str='error', n_permutations=1000, suffix=''){
  # Estimate Spatial error or lag model with given weight matrix
  if (model_str=='error'){
    model <- errorsarlm(model_equation, data=data, listw=weight_matrix, zero.policy=TRUE)
  }
  else if (model_str=='lag'){
    model <- lagsarlm(model_equation, data=data, listw=weight_matrix, zero.policy=TRUE)
  }

  # Because the moran.test function for retrieving the Moran's I is sensitive to irregularly distributed polygons, here we use a Monte Carlo method to bootstrap different polygon distribution (with moran.mc() function)
  mc_global <- moran.mc(model$residuals, weight_matrix, n_permutations, alternative="greater") # When the p value is significant we reject the null hypothesis that there is no significant autocorrelations among the variable, and accept that, the residual has spatial clustering
  
  # Plot the residual on the neighbourhood polygons
  col_str <- paste("res", suffix, sep="_") # Create column name using suffix
  data[col_str] <- model$residuals
  residuals <- qtm(data, col_str)
  
  return (list(model, mc_global, residuals))
}
```

```{r}
# Estimate spatial error model with adjacency matrix
# Combination of best predictors
error_model_final_adj_lst <- estimate_error_lag_model(model_equation=model_eq_final, data=neighbourhood_data, weight_matrix=Wadj, model_str='error', n_permutations=1000, suffix='final_adj')
error_model_final_adj <- error_model_final_adj_lst[[1]]
error_model_final_adj_moran <- error_model_final_adj_lst[[2]]
error_model_final_adj_res <- error_model_final_adj_lst[[3]]

# Inspect model
summary(error_model_final_adj)

# Describe Moran's I
print(error_model_final_adj_moran)
plot(error_model_final_adj_moran)

# Plot autocorrelation
error_model_final_adj_res 
```

```{r}
# Estimate spatial error model with inverse distance matrix
# Combination of best predictors
error_model_final_ids_lst <- estimate_error_lag_model(model_equation=model_eq_final, data=neighbourhood_data, weight_matrix=Wids, model_str='error', n_permutations=1000, suffix='final_ids')
error_model_final_ids <- error_model_final_ids_lst[[1]]
error_model_final_ids_moran <- error_model_final_ids_lst[[2]]
error_model_final_ids_res <- error_model_final_ids_lst[[3]]

# Inspect model
summary(error_model_final_ids)

# Describe Moran's I
print(error_model_final_ids_moran)
plot(error_model_final_ids_moran)

# Plot autocorrelation
error_model_final_ids_res 
```

```{r}
# Estimate spatial error model with inverse distance^2 matrix
# Combination of best predictors
error_model_final_ids2_lst <- estimate_error_lag_model(model_equation=model_eq_final, data=neighbourhood_data, weight_matrix=Wids2, model_str='error', n_permutations=1000, suffix='final_ids2')
error_model_final_ids2 <- error_model_final_ids2_lst[[1]]
error_model_final_ids2_moran <- error_model_final_ids2_lst[[2]]
error_model_final_ids2_res <- error_model_final_ids2_lst[[3]]

# Inspect model
summary(error_model_final_ids2)

# Describe Moran's I
print(error_model_final_ids2_moran)
plot(error_model_final_ids2_moran)

# Plot autocorrelation
error_model_final_ids2_res 
```

```{r}
# Estimate spatial error model with exp matrix
# Combination of best predictors
error_model_final_exp_lst <- estimate_error_lag_model(model_equation=model_eq_final, data=neighbourhood_data, weight_matrix=Wexpdis, model_str='error', n_permutations=1000, suffix='final_expdis')
error_model_final_exp <- error_model_final_exp_lst[[1]]
error_model_final_exp_moran <- error_model_final_exp_lst[[2]]
error_model_final_exp_res <- error_model_final_exp_lst[[3]]

# Inspect model
summary(error_model_final_exp)

# Describe Moran's I
print(error_model_final_exp_moran)
plot(error_model_final_exp_moran)

# Plot autocorrelation
error_model_final_exp_res 
```

```{r}
# Estimate spatial error model with inverse distance matrix
# Socio-economic predictors
error_model_economic_ids_lst <- estimate_error_lag_model(model_equation=model_eq_economic, data=neighbourhood_data, weight_matrix=Wids, model_str='error', n_permutations=1000, suffix='economic_ids')
error_model_economic_ids <- error_model_economic_ids_lst[[1]]
error_model_economic_ids_moran <- error_model_economic_ids_lst[[2]]
error_model_economic_ids_res <- error_model_economic_ids_lst[[3]]

# Inspect model
summary(error_model_economic_ids)

# Describe Moran's I
print(error_model_economic_ids_moran)
plot(error_model_economic_ids_moran)

# Plot autocorrelation
error_model_economic_ids_res 
```

```{r}
# Estimate spatial error model with inverse distance matrix
# Socio-demographic predictors
error_model_demographic_ids_lst <- estimate_error_lag_model(model_equation=model_eq_demographic, data=neighbourhood_data, weight_matrix=Wids, model_str='error', n_permutations=1000, suffix='demographic_ids')
error_model_demographic_ids <- error_model_demographic_ids_lst[[1]]
error_model_demographic_ids_moran <- error_model_demographic_ids_lst[[2]]
error_model_demographic_ids_res <- error_model_demographic_ids_lst[[3]]

# Inspect model
summary(error_model_demographic_ids)

# Describe Moran's I
print(error_model_demographic_ids_moran)
plot(error_model_demographic_ids_moran)

# Plot autocorrelation
error_model_demographic_ids_res 
```

```{r}
# Estimate spatial error model with inverse distance matrix
# Spatial location predictors
error_model_location_ids_lst <- estimate_error_lag_model(model_equation=model_eq_location, data=neighbourhood_data, weight_matrix=Wids, model_str='error', n_permutations=1000, suffix='location_ids')
error_model_location_ids <- error_model_location_ids_lst[[1]]
error_model_location_ids_moran <- error_model_location_ids_lst[[2]]
error_model_location_ids_res <- error_model_location_ids_lst[[3]]

# Inspect model
summary(error_model_location_ids)

# Describe Moran's I
print(error_model_location_ids_moran)
plot(error_model_location_ids_moran)

# Plot autocorrelation
error_model_location_ids_res 
```

```{r}
# Estimate spatial lag model with adjacency matrix
# Combination of best predictors
lag_model_final_adj_lst <- estimate_error_lag_model(model_equation=model_eq_final, data=neighbourhood_data, weight_matrix=Wadj, model_str='lag', n_permutations=1000, suffix='final_adj')
lag_model_final_adj <- lag_model_final_adj_lst[[1]]
lag_model_final_adj_moran <- lag_model_final_adj_lst[[2]]
lag_model_final_adj_res <- lag_model_final_adj_lst[[3]]

# Inspect model
summary(lag_model_final_adj)

# Describe Moran's I
print(lag_model_final_adj_moran)
plot(lag_model_final_adj_moran)

# Plot autocorrelation
lag_model_final_adj_res 
```

```{r}
# Estimate spatial lag model with inverse distance matrix
# Combination of best predictors
lag_model_final_ids_lst <- estimate_error_lag_model(model_equation=model_eq_final, data=neighbourhood_data, weight_matrix=Wids, model_str='lag', n_permutations=1000, suffix='final_ids')
lag_model_final_ids <- lag_model_final_ids_lst[[1]]
lag_model_final_ids_moran <- lag_model_final_ids_lst[[2]]
lag_model_final_ids_res <- lag_model_final_ids_lst[[3]]

# Inspect model
summary(lag_model_final_ids)

# Describe Moran's I
print(lag_model_final_ids_moran)
plot(lag_model_final_ids_moran)

# Plot autocorrelation
lag_model_final_ids_res 
```

```{r}
# Estimate spatial lag model with inverse distance^2 matrix
# Combination of best predictors
lag_model_final_ids2_lst <- estimate_error_lag_model(model_equation=model_eq_final, data=neighbourhood_data, weight_matrix=Wids2, model_str='lag', n_permutations=1000, suffix='final_ids2')
lag_model_final_ids2 <- lag_model_final_ids2_lst[[1]]
lag_model_final_ids2_moran <- lag_model_final_ids2_lst[[2]]
lag_model_final_ids2_res <- lag_model_final_ids2_lst[[3]]

# Inspect model
summary(lag_model_final_ids2)

# Describe Moran's I
print(lag_model_final_ids2_moran)
plot(lag_model_final_ids2_moran)

# Plot autocorrelation
lag_model_final_ids2_res 
```

```{r}
# Estimate spatial lag model with exp matrix
# Combination of best predictors
lag_model_final_exp_lst <- estimate_error_lag_model(model_equation=model_eq_final, data=neighbourhood_data, weight_matrix=Wexpdis, model_str='lag', n_permutations=1000, suffix='final_expdis')
lag_model_final_exp <- lag_model_final_exp_lst[[1]]
lag_model_final_exp_moran <- lag_model_final_exp_lst[[2]]
lag_model_final_exp_res <- lag_model_final_exp_lst[[3]]

# Inspect model
summary(lag_model_final_exp)

# Describe Moran's I
print(lag_model_final_exp_moran)
plot(lag_model_final_exp_moran)

# Plot autocorrelation
lag_model_final_exp_res 
```

```{r}
# Estimate spatial lag model with inverse distance matrix
# Socio-economic predictors
lag_model_economic_ids_lst <- estimate_error_lag_model(model_equation=model_eq_economic, data=neighbourhood_data, weight_matrix=Wids, model_str='lag', n_permutations=1000, suffix='economic_ids')
lag_model_economic_ids <- lag_model_economic_ids_lst[[1]]
lag_model_economic_ids_moran <- lag_model_economic_ids_lst[[2]]
lag_model_economic_ids_res <- lag_model_economic_ids_lst[[3]]

# Inspect model
summary(lag_model_economic_ids)

# Describe Moran's I
print(lag_model_economic_ids_moran)
plot(lag_model_economic_ids_moran)

# Plot autocorrelation
lag_model_economic_ids_res 
```

```{r}
# Estimate spatial lag model with inverse distance matrix
# Socio-demographic predictors
lag_model_demographic_ids_lst <- estimate_error_lag_model(model_equation=model_eq_demographic, data=neighbourhood_data, weight_matrix=Wids, model_str='lag', n_permutations=1000, suffix='demographic_ids')
lag_model_demographic_ids <- lag_model_demographic_ids_lst[[1]]
lag_model_demographic_ids_moran <- lag_model_demographic_ids_lst[[2]]
lag_model_demographic_ids_res <- lag_model_demographic_ids_lst[[3]]

# Inspect model
summary(lag_model_demographic_ids)

# Describe Moran's I
print(lag_model_demographic_ids_moran)
plot(lag_model_demographic_ids_moran)

# Plot autocorrelation
lag_model_demographic_ids_res 
```

```{r}
# Estimate spatial lag model with inverse distance matrix
# Spatial location predictors
lag_model_location_ids_lst <- estimate_error_lag_model(model_equation=model_eq_location, data=neighbourhood_data, weight_matrix=Wids, model_str='lag', n_permutations=1000, suffix='location_ids')
lag_model_location_ids <- lag_model_location_ids_lst[[1]]
lag_model_location_ids_moran <- lag_model_location_ids_lst[[2]]
lag_model_location_ids_res <- lag_model_location_ids_lst[[3]]

# Inspect model
summary(lag_model_location_ids)

# Describe Moran's I
print(lag_model_location_ids_moran)
plot(lag_model_location_ids_moran)

# Plot autocorrelation
lag_model_location_ids_res 
```

## Investigate non-stationarity with Geographically weighted regression model
Now the Geographically weighted regression models are trained, it is interesting to inspect the local patterns that have been found. For this purpose map the coefficients of interesting predictor variables and compare this to a map of the significance of this variable. 

```{r}
# Print results of model with model statistics
# Composite of most promising variables 
gwr_final_gauss
gwr_final_bisquare
```

```{r}
# Socio-economic variables
# gwr_economic_gauss
gwr_economic_bisquare
```

```{r}
# Socio-demographic variables
# gwr_demographic_gauss
gwr_demographic_bisquare
```

```{r}
# Spatial location variables
# gwr_location_gauss
gwr_location_bisquare
```

```{r}
# Put the Geographically Weighted Regression with adaptive kernel results in data frame
# Composite of most promising variables 
gwr_out_final_gauss <- as.data.frame(gwr_final_gauss$SDF)
gwr_out_final_bisquare <- as.data.frame(gwr_final_bisquare$SDF)
```

```{r}
# Socio-economic variables
# gwr_out_economic_gauss <- as.data.frame(gwr_economic_gauss$SDF)
gwr_out_economic_bisquare <- as.data.frame(gwr_economic_bisquare$SDF)
```

```{r}
# Socio-demographic variables
# gwr_out_demographic_gauss <- as.data.frame(gwr_demographic_gauss$SDF)
gwr_out_demographic_bisquare <- as.data.frame(gwr_demographic_bisquare$SDF)
```

```{r}
# Spatial location variables
# gwr_out_location_gauss <- as.data.frame(gwr_location_gauss$SDF)
gwr_out_location_bisquare <- as.data.frame(gwr_location_bisquare$SDF)
```

```{r}
# Join the local R2 for each GWR model to each neighborhood and display its distribution
# Composite of most promising variables 
neighbourhood_data$localR2 <- gwr_out_final_gauss$localR2
mapview::mapview(neighbourhood_data, zcol = "localR2", col.regions=brewer.pal(9, "RdYlGn")) 

neighbourhood_data$localR2 <- gwr_out_final_bisquare$localR2
mapview::mapview(neighbourhood_data, zcol = "localR2", col.regions=brewer.pal(9, "RdYlGn")) 
```

```{r}
# Socio-economic variables
# neighbourhood_data$localR2 <- gwr_out_economic_gauss$localR2
# mapview::mapview(neighbourhood_data, zcol = "localR2", col.regions=brewer.pal(9, "RdYlGn")) 

neighbourhood_data$localR2 <- gwr_out_economic_bisquare$localR2
mapview::mapview(neighbourhood_data, zcol = "localR2", col.regions=brewer.pal(9, "RdYlGn")) 
```

```{r}
# Socio-demographic variables
# neighbourhood_data$localR2 <- gwr_out_demographic_gauss$localR2
# mapview::mapview(neighbourhood_data, zcol = "localR2", col.regions=brewer.pal(9, "RdYlGn")) 

neighbourhood_data$localR2 <- gwr_out_demographic_bisquare$localR2
mapview::mapview(neighbourhood_data, zcol = "localR2", col.regions=brewer.pal(9, "RdYlGn")) 
```

```{r}
# Spatial location variables
# neighbourhood_data$localR2 <- gwr_out_location_gauss$localR2
# mapview::mapview(neighbourhood_data, zcol = "localR2", col.regions=brewer.pal(9, "RdYlGn")) 

neighbourhood_data$localR2 <- gwr_out_location_bisquare$localR2
mapview::mapview(neighbourhood_data, zcol = "localR2", col.regions=brewer.pal(9, "RdYlGn")) 
```

```{r}
#' Create two maps to compare Geographically Weighted Regression coefficients of a predictor variable with its significance levels by first joining these values to their respective neighbourhood polygons
#' 
#' @param data Dataset with the polygon geometry information to which to join the coefficient and significance values
#' @param gwr_results Data frame with results of trained Geographically Weighted Regression model. This is different for the model trained using spatial cross-validation and when spatial was not taken into account for cross-validation
#' @param predictor String with the name of the predictor variable to create these maps for
#' @param suffix String (default "") with a suffix for the predictor name when the coefficient and significance values are added as column to data. This can uniquely refer to the model used for training to get unique column names, e.g. "spatial".
#' 
#' @return list(gwr_coef, gwr_sig) list with as first element a map with coefficient values, and as second element a map with significance values of this variable
map_coefficient_var_sig <- function(data, gwr_results, predictor, suffix="") {
  # Determine the coefficient variability over space for all relevant predictors, after joining that with the neighbourhood polygons. This plot will now only be created and later be shown together with its predictor significance plot
  # Create column name for adding coefficient values to data
  acoef_str <- paste("acoef", predictor, suffix, sep="_") 
  # Join coefficient values with neighbourhoods
  data[acoef_str] <- gwr_results[,predictor]
  # Create map of coefficient values
  gwr_coef <- mapview::mapview(data, zcol = acoef_str)
  
  # Compute and map the statistical significance for variable using t-test. Plot this next to the map with its respective coefficient value distribution
  # Create column names for adding significance values to data
  pred_str_se <- paste(predictor, "se", sep="_")
  pred_str_at <- paste("at", predictor, sep="_")
  pred_str_at_cat <- paste(pred_str_at, "cat", sep="_")
  # Estimate the t-value for variable 
  t_pred <- gwr_results[,predictor] / gwr_results[,pred_str_se]
  # Categorize the t-value to statistical significance
  data[pred_str_at_cat] <- cut(t_pred,
                                    breaks=c(min(t_pred),
                                             -1.96, 1.96,
                                             max(t_pred)),
                                    labels=c("sig","nonsig", "sig"))
  # Make plot of the variable significance 
  gwr_sig <- mapview::mapview(data, zcol = pred_str_at_cat)
  
  # Compare the coefficient and significance maps of this variable
  return(list(gwr_coef, gwr_sig))
}
```

```{r}
# Create a list with string representation of the predictors in each equation
# Socio-economic variables
lst_economic_str <- list("gem_woning_waarde", "aant_ink_ont", "p_laag_ink")

# Socio-demographic variables
lst_demographic_str <- list("vrouw", "p_0_15_jaar", "p_15_25_jaar", "p_25_45_jaar", "p_45_65_jaar", "p_gescheiden", "p_ia_west", "p_ia_n_west")

# Spatial location variables
lst_location_str <- list("bev_dichth_km2", "aantal_bedrijf", "voortg_ond_3km", "dist_NN_voting_station")

# Composite of most promising variables 
lst_final_str <- list("bev_dichth_km2", "vrouw", "p_0_15_jaar", "p_15_25_jaar", "p_25_45_jaar", "p_45_65_jaar", "p_gescheiden", "p_ia_west", "p_ia_n_west", "aantal_bedrijf", "gem_woning_waarde", "aant_ink_ont", "p_laag_ink", "voortg_ond_3km", "dist_NN_voting_station")
```

```{r}
# Create lists with coefficient and variable significance maps for each trained GWR model
# Composite of most promising variables 
gwr_lst_coef_final_gauss <- list()
gwr_lst_sig_final_gauss <- list()
for (i in 1:length(lst_final_str)){
  gwr_lst_final_gauss <- map_coefficient_var_sig(data=neighbourhood_data, gwr_results=gwr_out_final_gauss, predictor=lst_final_str[[i]], suffix="")
  gwr_lst_coef_final_gauss[[i]] <- gwr_lst_final_gauss[[1]] 
  gwr_lst_sig_final_gauss[[i]] <- gwr_lst_final_gauss[[2]]
}
```

```{r}
gwr_lst_coef_final_bisquare <- list()
gwr_lst_sig_final_bisquare <- list()
for (i in 1:length(lst_final_str)){
  gwr_lst_final_bisquare <- map_coefficient_var_sig(data=neighbourhood_data, gwr_results=gwr_out_final_bisquare, predictor=lst_final_str[[i]], suffix="")
  gwr_lst_coef_final_bisquare[[i]] <- gwr_lst_final_bisquare[[1]] 
  gwr_lst_sig_final_bisquare[[i]] <- gwr_lst_final_bisquare[[2]]
}
```

```{r}
# Socio-economic variables
# gwr_lst_coef_economic_gauss <- list()
# gwr_lst_sig_economic_gauss <- list()
# for (i in 1:length(lst_economic_str)){
#   gwr_lst_economic_gauss <- map_coefficient_var_sig(data=neighbourhood_data, gwr_results=gwr_out_economic_gauss, predictor=lst_economic_str[[i]], suffix="")
#   gwr_lst_coef_economic_gauss[[i]] <- gwr_lst_economic_gauss[[1]] 
#   gwr_lst_sig_economic_gauss[[i]] <- gwr_lst_economic_gauss[[2]]
# }
```

```{r}
gwr_lst_coef_economic_bisquare <- list()
gwr_lst_sig_economic_bisquare <- list()
for (i in 1:length(lst_economic_str)){
  gwr_lst_economic_bisquare <- map_coefficient_var_sig(data=neighbourhood_data, gwr_results=gwr_out_economic_bisquare, predictor=lst_economic_str[[i]], suffix="")
  gwr_lst_coef_economic_bisquare[[i]] <- gwr_lst_economic_bisquare[[1]] 
  gwr_lst_sig_economic_bisquare[[i]] <- gwr_lst_economic_bisquare[[2]]
}
```

```{r}
# Socio-demographic variables
# gwr_lst_coef_demographic_gauss <- list()
# gwr_lst_sig_demographic_gauss <- list()
# for (i in 1:length(lst_demographic_str)){
#   gwr_lst_demographic_gauss <- map_coefficient_var_sig(data=neighbourhood_data, gwr_results=gwr_out_demographic_gauss, predictor=lst_demographic_str[[i]], suffix="")
#   gwr_lst_coef_demographic_gauss[[i]] <- gwr_lst_demographic_gauss[[1]] 
#   gwr_lst_sig_demographic_gauss[[i]] <- gwr_lst_demographic_gauss[[2]]
# }
```

```{r}
gwr_lst_coef_demographic_bisquare <- list()
gwr_lst_sig_demographic_bisquare <- list()
for (i in 1:length(lst_demographic_str)){
  gwr_lst_demographic_bisquare <- map_coefficient_var_sig(data=neighbourhood_data, gwr_results=gwr_out_demographic_bisquare, predictor=lst_demographic_str[[i]], suffix="")
  gwr_lst_coef_demographic_bisquare[[i]] <- gwr_lst_demographic_bisquare[[1]] 
  gwr_lst_sig_demographic_bisquare[[i]] <- gwr_lst_demographic_bisquare[[2]]
}
```

```{r}
# Spatial location variables
# gwr_lst_coef_location_gauss <- list()
# gwr_lst_sig_location_gauss <- list()
# for (i in 1:length(lst_location_str)){
#   gwr_lst_location_gauss <- map_coefficient_var_sig(data=neighbourhood_data, gwr_results=gwr_out_location_gauss, predictor=lst_location_str[[i]], suffix="")
#   gwr_lst_coef_location_gauss[[i]] <- gwr_lst_location_gauss[[1]] 
#   gwr_lst_sig_location_gauss[[i]] <- gwr_lst_location_gauss[[2]]
# }
```

```{r}
gwr_lst_coef_location_bisquare <- list()
gwr_lst_sig_location_bisquare <- list()
for (i in 1:length(lst_location_str)){
  gwr_lst_location_bisquare <- map_coefficient_var_sig(data=neighbourhood_data, gwr_results=gwr_out_location_bisquare, predictor=lst_location_str[[i]], suffix="")
  gwr_lst_coef_location_bisquare[[i]] <- gwr_lst_location_bisquare[[1]] 
  gwr_lst_sig_location_bisquare[[i]] <- gwr_lst_location_bisquare[[2]]
}
```

```{r}
# Compare maps of predictor coefficients and significance values 
# Composite of most promising variables 
for (i in 1:length(gwr_lst_coef_final_gauss)){
  show(gwr_lst_coef_final_gauss[[i]])
  show(gwr_lst_sig_final_gauss[[i]])
}
```

```{r}
for (i in 1:length(gwr_lst_coef_final_bisquare)){
  show(gwr_lst_coef_final_bisquare[[i]])
  show(gwr_lst_sig_final_bisquare[[i]])
}
```

```{r}
# Socio-economic variables
# for (i in 1:length(gwr_lst_coef_economic_gauss)){
#   show(gwr_lst_coef_economic_gauss[[i]])
#   show(gwr_lst_sig_economic_gauss[[i]])
# }
```

```{r}
for (i in 1:length(gwr_lst_coef_economic_bisquare)){
  show(gwr_lst_coef_economic_bisquare[[i]])
  show(gwr_lst_sig_economic_bisquare[[i]])
}
```

```{r}
# Socio-demographic variables
# for (i in 1:length(gwr_lst_coef_demographic_gauss)){
#   show(gwr_lst_coef_demographic_gauss[[i]])
#   show(gwr_lst_sig_demographic_gauss[[i]])
# }
```

```{r}
for (i in 1:length(gwr_lst_coef_demographic_bisquare)){
  show(gwr_lst_coef_demographic_bisquare[[i]])
  show(gwr_lst_sig_demographic_bisquare[[i]])
}
```

```{r}
# Spatial location variables
# for (i in 1:length(gwr_lst_coef_location_gauss)){
#   show(gwr_lst_coef_location_gauss[[i]])
#   show(gwr_lst_sig_location_gauss[[i]])
# }
```

```{r}
for (i in 1:length(gwr_lst_coef_location_bisquare)){
  show(gwr_lst_coef_location_bisquare[[i]])
  show(gwr_lst_sig_location_bisquare[[i]])
}
```

## Inspect important variables of random forest model
To investigate what variables are most important for the Random Forest model to make its predictions, the feature importance is determined and plotted. This shows which variables were most important in predicting the turnout. The importance is first shown based on the impurity metric and after in an interactive model based on permutation, which is more robust. In this interactive model also the partial dependence of different variables can be explored to check their relations. Note that this can take quite a bit of time to run.

```{r}
# Inspect more model statistics 
# Without spatial cross validation
# Composite of best predictors
rf_model_final <- rf_val_fit_geo_final %>% pluck(".workflow", 1) %>% extract_fit_engine() 
rf_model_final
```

```{r}
# Inspect more model statistics 
# With spatial cross validation
# Composite of best predictors
rf_model_spatial_final <- rf_val_fit_geo_spatial_final %>% pluck(".workflow", 1) %>% extract_fit_engine() 
rf_model_spatial_final
```

```{r}
# Inspect more model statistics 
# With spatial cross validation
# Socio-economic
rf_model_spatial_economic <- rf_val_fit_geo_spatial_economic %>% pluck(".workflow", 1) %>% extract_fit_engine() 
rf_model_spatial_economic
```

```{r}
# Inspect more model statistics 
# With spatial cross validation
# Socio-demographic
rf_model_spatial_demographic <- rf_val_fit_geo_spatial_demographic %>% pluck(".workflow", 1) %>% extract_fit_engine() 
rf_model_spatial_demographic
```

```{r}
# Inspect more model statistics 
# With spatial cross validation
# Spatial location
rf_model_spatial_location <- rf_val_fit_geo_spatial_location %>% pluck(".workflow", 1) %>% extract_fit_engine() 
rf_model_spatial_location
```

```{r}
# Create a list with English string representation of the predictors in each equation for plotting purposes
# Socio-economic variables
features_economic_str <- list("Avg. house value", "No. income earners", "% Low income")

# Socio-demographic variables
features_demographic_str <- list("% Female", "% 0-15 y/o", "% 15-25 y/o", "% 25-45 y/o", "% 45-65 y/o", "% Divorced", "% Western Immigrant", "% Non-western Immigrant")

# Spatial location variables
features_location_str <- list("Pop. Density per km2", "No. Companies", "High School within 3km", "Distance to voting station")

# Composite of most promising variables 
features_final_str <- list("Pop. Density per km2", "% Female", "% 0-15 y/o", "% 15-25 y/o", "% 25-45 y/o", "% 45-65 y/o", "% Divorced", "% Western Immigrant", "% Non-western Immigrant", "No. Companies", "Avg. house value", "No. income earners", "% Low income", "High School within 3km", "Distance to voting station")
```

```{r}
# Plot the variable importance based on permutation (because on that is trained in tidymodels)
# Without spatial cross-validation
# Composite of best predictors
rf_val_fit_geo_final %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>%
vip::vip(num_features = 15, idth = 0.5, aesthetics = list(fill = "purple2"), include_type = T) + scale_x_discrete(labels=features_final_str)
```

```{r}
# Plot the variable importance based on permutation (because on that is trained in tidymodels)
# With spatial cross-validation
# Composite of best predictors
rf_val_fit_geo_spatial_final %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>% vip::vip(num_features = 15, idth = 0.5, aesthetics = list(fill = "purple2"), include_type = T) + scale_x_discrete(labels=features_final_str)
```

```{r}
# Plot the variable importance based on permutation (because on that is trained in tidymodels)
# With spatial cross-validation
# Socio-economic
rf_val_fit_geo_spatial_economic %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>% vip::vip(num_features = 3, idth = 0.5, aesthetics = list(fill = "purple2"), include_type = T) + scale_x_discrete(labels=features_economic_str)
```

```{r}
# Plot the variable importance based on permutation (because on that is trained in tidymodels)
# With spatial cross-validation
# Socio-demographic
rf_val_fit_geo_spatial_demographic %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>% vip::vip(num_features = 8, idth = 0.5, aesthetics = list(fill = "purple2"), include_type = T) + scale_x_discrete(labels=features_demographic_str)
```

```{r}
# Plot the variable importance based on permutation (because on that is trained in tidymodels)
# With spatial cross-validation
# Spatial location
rf_val_fit_geo_spatial_location %>% pluck(".workflow", 1) %>% extract_fit_parsnip() %>% vip::vip(num_features = 4, idth = 0.5, aesthetics = list(fill = "purple2"), include_type = T) + scale_x_discrete(labels=features_location_str)
```